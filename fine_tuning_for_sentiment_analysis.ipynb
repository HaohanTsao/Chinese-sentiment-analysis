{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17Mp0aXZJpIVS3LMkRllRje6zxMCD26u8","authorship_tag":"ABX9TyMfHWt6um1xcZGguqVpy4WM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Fine Tuning BERT for Sentiment Analysis"],"metadata":{"id":"6hSzHyUjR2IT"}},{"cell_type":"markdown","source":["æ­¤æª”æ¡ˆåƒ…ç‚ºå»ºç«‹training pipeline èˆ‡æ¸¬è©¦çš„æª”æ¡ˆ"],"metadata":{"id":"kI_TpP2Fr45l"}},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MSUyshOSzPn","executionInfo":{"status":"ok","timestamp":1685541779043,"user_tz":-480,"elapsed":16542,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"dae1ca67-6288-49f5-8b74-1d9ca9177039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}]},{"cell_type":"code","source":["# package\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","from transformers import BertModel, BertTokenizer"],"metadata":{"id":"BROMFDKASESS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re"],"metadata":{"id":"xjBW90Q70ggc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns"],"metadata":{"id":"Tx348QmaGE6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/pythonæ©Ÿå™¨å­¸ç¿’å°ˆæ¡ˆ')"],"metadata":{"id":"q_wtbwcFftj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# æº–å‚™æ¸¬è©¦è³‡æ–™\n","selected_columns = ['content', 'sentiment']\n","folder_path = 'raw_data'\n","file_path = ['db2022_hw5_dcard_job.csv', 'db2022_hw5_dcard_food.csv'] \n","bert_test_data = pd.DataFrame()\n","for filename in os.listdir(folder_path):\n","  if filename in file_path:\n","    df_temp = pd.read_csv(f'{folder_path}/{filename}')\n","    bert_test_data = pd.concat([bert_test_data, df_temp[selected_columns]], ignore_index=True)"],"metadata":{"id":"NhxUIXHjiSZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_sentiments = ['N', 'M', 'P']\n","bert_test_data = bert_test_data[bert_test_data['sentiment'].isin(valid_sentiments)]"],"metadata":{"id":"ZzxyNWRLsEQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.drop_duplicates(inplace=True)\n","bert_test_data = bert_test_data.dropna(axis=0, how='any', subset=['content'])"],"metadata":{"id":"UTw1rnqDysuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugV6T7vizBIA","executionInfo":{"status":"ok","timestamp":1685541791374,"user_tz":-480,"elapsed":16,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"c37f366a-0a36-4b73-b838-e3a5c3bad09e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(77320, 2)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["bert_test_data[\"sentiment\"] = bert_test_data[\"sentiment\"].replace({'N': 0, 'M': 1, 'P': 2})"],"metadata":{"id":"BhxO7b_izfJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# æ–‡æœ¬æ¸…ç†å‡½æ•¸\n","def text_clean(content):\n","  cleaned_content = content\n","  cleaned_content = re.sub(r'[\\n\\r]', '', cleaned_content) # æ›è¡Œç¬¦è™Ÿ\n","  cleaned_content = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', cleaned_content) # ç§»é™¤url\n","  cleaned_content = re.sub(r'<.*?>', '', cleaned_content) # ç§»é™¤htmlæ¨™ç±¤\n","  cleaned_content = re.sub(r'\\d+', '', cleaned_content) # æ•¸å­—\n","  cleaned_content = re.sub(r'[^\\w\\s]', '', cleaned_content) # ç§»é™¤æ¨™é»ç¬¦è™Ÿ\n","  cleaned_content = re.sub(r\"\\s+\", \"\", cleaned_content) # æ¸…é™¤ç©ºæ ¼\n","  return cleaned_content"],"metadata":{"id":"iAPODlaizvwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data['cleaned_content'] = bert_test_data['content'].apply(text_clean)"],"metadata":{"id":"YfuBEW5N0erq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"Sl9u1r6B1wb6","executionInfo":{"status":"ok","timestamp":1685541798812,"user_tz":-480,"elapsed":10,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"ec203697-9d3e-4e16-c6ae-02299e0af3c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             content  sentiment  \\\n","0  https://megapx-assets.dcard.tw/images/5a86504a...          1   \n","1  è½èªªæœ‰æ°´é¤ƒåƒåˆ°é£½ ä½†ç‚ºä»€éº¼æ²’æœ‰é›è›‹åƒåˆ°é£½å•Šï¼Ÿ æˆ‘é€™å€‹äººæœ€æ„›åƒé›è›‹äº† ä¸€å¤©æœ€é«˜ç´€éŒ„å¯ä»¥åƒ25é¡†...          1   \n","2  https://megapx-assets.dcard.tw/images/8086527f...          1   \n","3  ç¾åœ¨ä¸ç®¡åƒä»€éº¼æ³¡éºµï¼ˆç”¨ç…®çš„ï¼‰éƒ½ä¸€å®šæœƒåŠ é®®å¥¶ï¼ï¼ï¼ çœŸçš„å¾ˆå¥½åƒğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚  æ‹‰éºµé“ã€è¾›æ‹‰éºµã€ğŸ…æ³¡...          2   \n","4  https://i.imgur.com/y9y3Nhv.jpg å”æšé›çƒ¤é£¯ç³° $45 å”æšç‚¸...          1   \n","\n","                                     cleaned_content  \n","0                                                     \n","1  è½èªªæœ‰æ°´é¤ƒåƒåˆ°é£½ä½†ç‚ºä»€éº¼æ²’æœ‰é›è›‹åƒåˆ°é£½å•Šæˆ‘é€™å€‹äººæœ€æ„›åƒé›è›‹äº†ä¸€å¤©æœ€é«˜ç´€éŒ„å¯ä»¥åƒé¡†å¦‚æœèƒ½æœ‰é€™æ¨£...  \n","2                                                     \n","3        ç¾åœ¨ä¸ç®¡åƒä»€éº¼æ³¡éºµç”¨ç…®çš„éƒ½ä¸€å®šæœƒåŠ é®®å¥¶çœŸçš„å¾ˆå¥½åƒæ‹‰éºµé“è¾›æ‹‰éºµæ³¡éºµå„ç¨®æ³¡éºµéƒ½ä¸€å®šè¦åŠ é®®å¥¶  \n","4  å”æšé›çƒ¤é£¯ç³°å”æšç‚¸é›å‰ç‡’è±šéª¨æ‹‰éºµé€™æ¬¡åƒ¹æ ¼åœ¨è¶…å•†ä¾†èªªéƒ½åè²´æ¯”è¼ƒæ¨è–¦åšé®®çš„æ˜¯å”æšç‚¸é›å’Œçƒ¤é£¯ç³°å”æš...  "],"text/html":["\n","  <div id=\"df-37750018-f7c5-450d-a3ab-b84cedd18e7c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>sentiment</th>\n","      <th>cleaned_content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://megapx-assets.dcard.tw/images/5a86504a...</td>\n","      <td>1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>è½èªªæœ‰æ°´é¤ƒåƒåˆ°é£½ ä½†ç‚ºä»€éº¼æ²’æœ‰é›è›‹åƒåˆ°é£½å•Šï¼Ÿ æˆ‘é€™å€‹äººæœ€æ„›åƒé›è›‹äº† ä¸€å¤©æœ€é«˜ç´€éŒ„å¯ä»¥åƒ25é¡†...</td>\n","      <td>1</td>\n","      <td>è½èªªæœ‰æ°´é¤ƒåƒåˆ°é£½ä½†ç‚ºä»€éº¼æ²’æœ‰é›è›‹åƒåˆ°é£½å•Šæˆ‘é€™å€‹äººæœ€æ„›åƒé›è›‹äº†ä¸€å¤©æœ€é«˜ç´€éŒ„å¯ä»¥åƒé¡†å¦‚æœèƒ½æœ‰é€™æ¨£...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://megapx-assets.dcard.tw/images/8086527f...</td>\n","      <td>1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ç¾åœ¨ä¸ç®¡åƒä»€éº¼æ³¡éºµï¼ˆç”¨ç…®çš„ï¼‰éƒ½ä¸€å®šæœƒåŠ é®®å¥¶ï¼ï¼ï¼ çœŸçš„å¾ˆå¥½åƒğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚  æ‹‰éºµé“ã€è¾›æ‹‰éºµã€ğŸ…æ³¡...</td>\n","      <td>2</td>\n","      <td>ç¾åœ¨ä¸ç®¡åƒä»€éº¼æ³¡éºµç”¨ç…®çš„éƒ½ä¸€å®šæœƒåŠ é®®å¥¶çœŸçš„å¾ˆå¥½åƒæ‹‰éºµé“è¾›æ‹‰éºµæ³¡éºµå„ç¨®æ³¡éºµéƒ½ä¸€å®šè¦åŠ é®®å¥¶</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://i.imgur.com/y9y3Nhv.jpg å”æšé›çƒ¤é£¯ç³° $45 å”æšç‚¸...</td>\n","      <td>1</td>\n","      <td>å”æšé›çƒ¤é£¯ç³°å”æšç‚¸é›å‰ç‡’è±šéª¨æ‹‰éºµé€™æ¬¡åƒ¹æ ¼åœ¨è¶…å•†ä¾†èªªéƒ½åè²´æ¯”è¼ƒæ¨è–¦åšé®®çš„æ˜¯å”æšç‚¸é›å’Œçƒ¤é£¯ç³°å”æš...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37750018-f7c5-450d-a3ab-b84cedd18e7c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-37750018-f7c5-450d-a3ab-b84cedd18e7c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-37750018-f7c5-450d-a3ab-b84cedd18e7c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# è¼‰å…¥é è¨“ç·´çš„æ¨¡å‹\n","bert_model = BertModel.from_pretrained(\"/content/drive/MyDrive/pythonæ©Ÿå™¨å­¸ç¿’å°ˆæ¡ˆ/model_file\")\n","tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/pythonæ©Ÿå™¨å­¸ç¿’å°ˆæ¡ˆ/model_file\")"],"metadata":{"id":"UkgJnVs2fZyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_sentence = \"é€™æ˜¯ä¸€å€‹æ¸¬è©¦çš„å¥å­\""],"metadata":{"id":"0qCI5r9vtjPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = tokenizer.tokenize(sample_sentence)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(f' Sentence: {sample_sentence}')\n","print(f'   Tokens: {tokens}')\n","print(f'Token IDs: {token_ids}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaxweSI-uOdC","executionInfo":{"status":"ok","timestamp":1685541807938,"user_tz":-480,"elapsed":49,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"b47b7257-6cc5-4167-ab43-9a23d52701f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Sentence: é€™æ˜¯ä¸€å€‹æ¸¬è©¦çš„å¥å­\n","   Tokens: ['é€™', 'æ˜¯', 'ä¸€', 'å€‹', 'æ¸¬', 'è©¦', 'çš„', 'å¥', 'å­']\n","Token IDs: [6857, 3221, 671, 943, 3947, 6275, 4638, 1368, 2094]\n"]}]},{"cell_type":"markdown","source":["### ä¸‹é¢é€™æ®µæ˜¯ç›´æ¥è¤‡è£½ï¼Œåƒæ•¸çš„æ„ç¾©è¦å†ç ”ç©¶(é•·åº¦ç­‰ç­‰)ï¼Œencode_plusæ˜¯æŠŠæ–‡æœ¬è½‰æ›ç‚ºæ¨¡å‹å¯ç†è§£çš„è¼¸å…¥æ ¼å¼"],"metadata":{"id":"sdpssfFy32O3"}},{"cell_type":"code","source":["encoding = tokenizer.encode_plus(\n","  sample_sentence,\n","  max_length=32,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',  # Return PyTorch tensors\n",")\n","\n","encoding.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aArt9YJy30e3","executionInfo":{"status":"ok","timestamp":1685541807938,"user_tz":-480,"elapsed":46,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"50924bca-6286-4352-bf52-dc4aefde7d10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(len(encoding['input_ids'][0]))\n","encoding['input_ids'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhNZX1H_5qYH","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":40,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"be946077-a657-4115-bf64-f6116e00b3fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 101, 6857, 3221,  671,  943, 3947, 6275, 4638, 1368, 2094,  102,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["print(len(encoding['attention_mask'][0]))\n","encoding['attention_mask']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlyFjkt1569A","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":36,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"b64db75b-6b9a-4c0e-8fc7-c14ae42443a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# We can inverse the tokenization to have a look at the special tokens:\n","tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92IP24hE59RV","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":32,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"77c5b7f0-e140-459a-8e3f-ab237a9c3270"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," 'é€™',\n"," 'æ˜¯',\n"," 'ä¸€',\n"," 'å€‹',\n"," 'æ¸¬',\n"," 'è©¦',\n"," 'çš„',\n"," 'å¥',\n"," 'å­',\n"," '[SEP]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]']"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### Choosing Sequence Lengthï¼Œå¯¦éš›è³‡æ–™è¦å†èª¿æ•´"],"metadata":{"id":"iWpl_ONZHHgR"}},{"cell_type":"code","source":["# ç”¨ä¸€å€‹æ›´å°çš„dataset ç•¶æ¸¬è©¦\n","test_data = bert_test_data.head(2000)\n"],"metadata":{"id":"YmvQHpa4Mxid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"PTo_8BvJS_ns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### å»ºç«‹pytorch dataset"],"metadata":{"id":"CmtqVdaVVgpA"}},{"cell_type":"code","source":["class ContentDataset(Dataset):\n","\n","  def __init__(self, contents, targets, tokenizer, max_len):\n","    self.contents = contents\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","  \n","  def __len__(self):\n","    return len(self.contents)\n","  \n","  def __getitem__(self, item):\n","    content = str(self.contents[item])\n","    target = self.targets[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","      content,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","    )\n","\n","    return {\n","      'content_text': content,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }"],"metadata":{"id":"ld0YOhy0JsS6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["åˆ†å‰²è³‡æ–™"],"metadata":{"id":"Y4EswpdAVaHm"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","df_train, df_test = train_test_split(test_data, test_size=0.1, random_state=2023)\n","df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=2023)"],"metadata":{"id":"8MwgqEiMPlIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.shape, df_val.shape, df_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGvUmXIFSFfW","executionInfo":{"status":"ok","timestamp":1685541807941,"user_tz":-480,"elapsed":29,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"55590b0d-e88f-4674-939a-c208d38fd47e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1800, 3), (100, 3), (100, 3))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = ContentDataset(\n","    contents=df['cleaned_content'].to_numpy(),\n","    targets=df['sentiment'].to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )"],"metadata":{"id":"Jj7K0ZsaSZo6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["é€™é‚Šçš„batch sizeè·Ÿmax_lengthå…ˆç…§æŠ„"],"metadata":{"id":"hxqtFhUAWQkM"}},{"cell_type":"code","source":["BATCH_SIZE = 16\n","MAX_LENGTH = 160\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_LENGTH, BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsme7O6qVNTd","executionInfo":{"status":"ok","timestamp":1685541807941,"user_tz":-480,"elapsed":26,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"4af52c31-65f3-42cd-9b24-da8b42fdc781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["# çœ‹ä¸€ä¸‹é•·ç›¸\n","data = next(iter(train_data_loader))\n","data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m87fVK0XWKBN","executionInfo":{"status":"ok","timestamp":1685541808469,"user_tz":-480,"elapsed":551,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"27d3ae1b-d35c-4ecb-bb2d-f52fabec0dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['content_text', 'input_ids', 'attention_mask', 'targets'])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["print(data['content_text'][1])\n","print(data['input_ids'].shape)\n","print(data['attention_mask'].shape)\n","print(data['targets'].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70iJhKVEWOUt","executionInfo":{"status":"ok","timestamp":1685541985169,"user_tz":-480,"elapsed":10,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"0ab35747-0d8a-4950-b6eb-de8092e76368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["æƒ³è«‹å•å¤§å®¶åŸæœ¬åœ¨å¸«å¤§çš„é˜¿è«¾å¯éº—é¤…å°é¢æœ‰ä¸€å€‹å¯éº—é¤…çš„æ”¤å­ä¸çŸ¥é“å¾Œä¾†æ¬å®¶æ¬åˆ°å“ªäº†æŸ¥éƒ½æŸ¥ä¸åˆ°å¸Œæœ›æœ‰äººèƒ½æŒ‡é»è¿·æ´¥è¬è¬\n","torch.Size([16, 160])\n","torch.Size([16, 160])\n","torch.Size([16])\n"]}]},{"cell_type":"markdown","source":["## Sentiment classifier"],"metadata":{"id":"GF_SAbYaW7Fm"}},{"cell_type":"code","source":["encoding.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QS2_WREyZHrF","executionInfo":{"status":"ok","timestamp":1685542345840,"user_tz":-480,"elapsed":518,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"af3eda07-fa52-4e6d-b388-7b194326820c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# ç”¨å‰›å‰›ç¤ºç¯„çš„å¥å­çœ‹ä¸€ä¸‹é•·ç›¸\n","temp = bert_model(\n","  input_ids=encoding['input_ids'], \n","  attention_mask=encoding['attention_mask']\n",")"],"metadata":{"id":"Rjt_dVWpXDv_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_hidden_state = temp.last_hidden_state\n","pooled_output = temp.pooler_output"],"metadata":{"id":"sm1lIo20u5s8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"],"metadata":{"id":"ck_qJwTGX23a"}},{"cell_type":"code","source":["last_hidden_state.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlK7XGEgX1Ik","executionInfo":{"status":"ok","timestamp":1685285000228,"user_tz":-480,"elapsed":25,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"7946880c-1add-4777-85b6-61b53a5c519f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 768])"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"],"metadata":{"id":"frRJIMKsv4Vg"}},{"cell_type":"code","source":["bert_model.config.hidden_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVNMpnDAwLjS","executionInfo":{"status":"ok","timestamp":1685285000229,"user_tz":-480,"elapsed":23,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"64f03010-d96c-4b0c-fd86-544a995cc72d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["You can think of the pooled_output as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"],"metadata":{"id":"RQufBoiCwc4B"}},{"cell_type":"code","source":["pooled_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJeSg0EFwgsg","executionInfo":{"status":"ok","timestamp":1685285000229,"user_tz":-480,"elapsed":18,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"f27eedb1-bf6f-43b5-a727-2f3e012c805b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 768])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["We can use all of this knowledge to create a classifier that uses the BERT model:"],"metadata":{"id":"atGTrKDexAfu"}},{"cell_type":"code","source":["from torch import nn, optim\n","import torch.nn.functional as F"],"metadata":{"id":"OAK27xHYyFNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SentimentClassifier(nn.Module):\n","\n","  def __init__(self, n_classes):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(\"/content/drive/MyDrive/pythonæ©Ÿå™¨å­¸ç¿’å°ˆæ¡ˆ/model_file\")\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    outputs = self.bert(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","    )\n","    pooled_output = outputs[1]\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"metadata":{"id":"L2tjed_HxFXB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### æ¶GPU"],"metadata":{"id":"CqmlCwxTIZmm"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gW8okDm1TOx","executionInfo":{"status":"ok","timestamp":1685285000230,"user_tz":-480,"elapsed":15,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"236c4f78-6b42-49fc-d60d-67f254a98d59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 28 14:43:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"id":"5qpiheuw1ZLI","executionInfo":{"status":"ok","timestamp":1685285000741,"user_tz":-480,"elapsed":10,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"516056a4-8f33-4de6-a8cf-670645f1173e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["class_names = ['N', 'M', 'P']\n","model = SentimentClassifier(len(class_names))\n","model = model.to(device)"],"metadata":{"id":"eGkXCQjm2U0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = torch.tensor(data['input_ids']).to(device)\n","attention_mask = torch.tensor(data['attention_mask']).to(device)\n","# input_ids = torch.tensor(data['input_ids'])\n","# attention_mask = torch.tensor(data['attention_mask'])\n","\n","print(input_ids.shape) # batch size x seq length\n","print(attention_mask.shape) # batch size x seq length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8niFaoUn3xC5","executionInfo":{"status":"ok","timestamp":1685285005736,"user_tz":-480,"elapsed":20,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"a573f963-8e9a-4da9-e448-1e4478dafec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 160])\n","torch.Size([16, 160])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-43-fd7f036b06ac>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  input_ids = torch.tensor(data['input_ids']).to(device)\n","<ipython-input-43-fd7f036b06ac>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_mask = torch.tensor(data['attention_mask']).to(device)\n"]}]},{"cell_type":"markdown","source":["To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"],"metadata":{"id":"Xq3iqvaB4Uve"}},{"cell_type":"code","source":["print(type(input_ids))\n","print(type(attention_mask))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdxCSSn_868y","executionInfo":{"status":"ok","timestamp":1685285005737,"user_tz":-480,"elapsed":13,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"4d814e60-7484-4965-b2c2-ec670cfe1044"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["# æˆ‘ä¹Ÿä¸çŸ¥é“é€™åœ¨å¹¹å˜›\n","# F.softmax(model(input_ids, attention_mask), dim=1)"],"metadata":{"id":"0NyggrUp4YUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trainning"],"metadata":{"id":"Df5K8Zw4-wTP"}},{"cell_type":"code","source":["from transformers import AdamW, get_linear_schedule_with_warmup"],"metadata":{"id":"S1_-B3P8-z4b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ç‚ºäº†é‡ç¾BERTè«–æ–‡ä¸­çš„è¨“ç·´éç¨‹ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨Hugging Faceæä¾›çš„AdamWå„ªåŒ–å™¨ã€‚å®ƒä¿®æ­£äº†æ¬Šé‡è¡°æ¸›ï¼ˆweight decayï¼‰ï¼Œå› æ­¤èˆ‡åŸå§‹è«–æ–‡ä¸­çš„æ–¹æ³•é¡ä¼¼ã€‚æˆ‘å€‘é‚„å°‡ä½¿ç”¨æ²’æœ‰Warmupæ­¥é©Ÿçš„ç·šæ€§å­¸ç¿’ç‡èª¿æ•´å™¨ï¼ˆschedulerï¼‰ï¼š"],"metadata":{"id":"pto39yeM_-6J"}},{"cell_type":"markdown","source":["ä¸‹é¢é€™æ®µæ‡‰è©²æ˜¯èª¿åƒæ•¸çš„é‡é»"],"metadata":{"id":"5t9ssVIGBiGn"}},{"cell_type":"code","source":["EPOCHS = 10\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","# loss_fn = nn.CrossEntropyLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1n74vS7i_J3J","executionInfo":{"status":"ok","timestamp":1685285009214,"user_tz":-480,"elapsed":17,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"759afb74-c8dd-44e1-ac46-febdc026f77d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["æˆ‘å€‘å¦‚ä½•å¾—å‡ºæ‰€æœ‰çš„è¶…åƒæ•¸ï¼ŸBERTçš„ä½œè€…å°å¾®èª¿æ¨¡å‹æå‡ºäº†ä¸€äº›å»ºè­°ï¼š\n","\n","Batch sizeï¼š16ã€32\n","\n","å­¸ç¿’ç‡ï¼ˆAdamï¼‰ï¼š5e-5ã€3e-5ã€2e-5\n","\n","Number of epochsï¼š2ã€3ã€4\n","\n","é€™é‚Šå°‡å¿½ç•¥å°æ–¼è¨“ç·´epochsæ•¸çš„å»ºè­°ï¼Œä½†éµå¾ªå…¶ä»–çš„å»ºè­°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¢åŠ æ‰¹æ¬¡å¤§å°å¯ä»¥é¡¯è‘—æ¸›å°‘è¨“ç·´æ™‚é–“ï¼Œä½†æœƒé™ä½æ¨¡å‹çš„æº–ç¢ºåº¦ã€‚\n","\n","è®“æˆ‘å€‘ç¹¼çºŒç·¨å¯«ä¸€å€‹è¼”åŠ©å‡½æ•¸ï¼Œç”¨æ–¼è¨“ç·´æˆ‘å€‘çš„æ¨¡å‹ä¸€å€‹epochï¼š"],"metadata":{"id":"QOF-wH-A_dDE"}},{"cell_type":"code","source":["# using gpu\n","def train_epoch_gpu(\n","  model, \n","  data_loader, \n","  loss_fn, \n","  optimizer, \n","  device, \n","  scheduler, \n","  n_examples\n","):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    targets = d[\"targets\"].to(device)\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(preds == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"Y0lL2pDUAN-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# using cpu\n","def train_epoch_cpu(\n","  model, \n","  data_loader, \n","  loss_fn, \n","  optimizer, \n","  scheduler, \n","  n_examples\n","):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    input_ids = d[\"input_ids\"]\n","    attention_mask = d[\"attention_mask\"]\n","    targets = d[\"targets\"]\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(preds == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"KfGqZ2lM_wPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["èª¿åº¦å™¨åœ¨æ¯æ¬¡å°‡ä¸€å€‹batché¤µçµ¦æ¨¡å‹æ™‚è¢«èª¿ç”¨ã€‚æˆ‘å€‘é€šéä½¿ç”¨clip_grad_norm_ä¾†é¿å…æ¢¯åº¦çˆ†ç‚¸ï¼Œå°æ¨¡å‹çš„æ¢¯åº¦é€²è¡Œè£å‰ªã€‚é€™ä¸€æ®µä¹Ÿå¯ä»¥åšç‚ºèª¿æ•´çš„æ ¹æ“šã€‚\n","\n","é€™ä¸€æ®µç¨‹å¼ç¢¼æ˜¯è¨“ç·´éç¨‹ä¸­çš„ä¸€å€‹é‡è¦æ­¥é©Ÿï¼Œç”¨æ–¼åŸ·è¡Œåå‘å‚³æ’­å’Œåƒæ•¸æ›´æ–°ã€‚\n","\n","1. `loss.backward()`: é€™å€‹æ–¹æ³•è¨ˆç®—æå¤±å°æ–¼æ¨¡å‹åƒæ•¸çš„æ¢¯åº¦ã€‚é€šéèª¿ç”¨é€™å€‹æ–¹æ³•ï¼Œæ¨¡å‹æœƒæ ¹æ“šç•¶å‰çš„æå¤±å€¼è¨ˆç®—æ¯å€‹åƒæ•¸çš„æ¢¯åº¦ã€‚\n","\n","2. `nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)`: é€™å€‹å‡½æ•¸ç”¨æ–¼æ¢¯åº¦è£å‰ªï¼Œä»¥é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸çš„å•é¡Œã€‚æ¢¯åº¦è£å‰ªçš„ç›®çš„æ˜¯é™åˆ¶æ¢¯åº¦çš„ç¯„åœï¼Œç¢ºä¿å…¶ä¸è¶…éé å®šçš„æœ€å¤§ç¯„åœã€‚åœ¨é€™è£¡ï¼Œæˆ‘å€‘ä½¿ç”¨`max_norm`åƒæ•¸è¨­å®šæ¢¯åº¦çš„æœ€å¤§ç¯„åœç‚º1.0ã€‚\n","\n","3. `optimizer.step()`: é€™å€‹æ–¹æ³•æ ¹æ“šè¨ˆç®—å¾—åˆ°çš„æ¢¯åº¦æ›´æ–°æ¨¡å‹çš„åƒæ•¸ã€‚å„ªåŒ–å™¨æœƒæ ¹æ“šè¨­å®šçš„å­¸ç¿’ç‡å’Œæ¢¯åº¦æ›´æ–°ç­–ç•¥ä¾†æ›´æ–°åƒæ•¸çš„å€¼ï¼Œä½¿å¾—æå¤±å‡½æ•¸ä¸‹é™ã€‚\n","\n","4. `scheduler.step()`: é€™å€‹æ–¹æ³•ç”¨æ–¼èª¿æ•´å„ªåŒ–å™¨çš„å­¸ç¿’ç‡ã€‚åœ¨é€™è£¡ä½¿ç”¨çš„æ˜¯ç·šæ€§å­¸ç¿’ç‡èª¿æ•´å™¨(`get_linear_schedule_with_warmup`)ï¼Œå®ƒæœƒæ ¹æ“šè¨­å®šçš„åƒæ•¸åœ¨æ¯å€‹è¨“ç·´æ­¥é©Ÿä¸­èª¿æ•´å­¸ç¿’ç‡çš„å€¼ã€‚\n","\n","5. `optimizer.zero_grad()`: é€™å€‹æ–¹æ³•å°‡æ¨¡å‹åƒæ•¸çš„æ¢¯åº¦æ¸…é›¶ï¼Œä»¥ä¾¿é€²è¡Œä¸‹ä¸€å€‹batchçš„è¨ˆç®—ã€‚åœ¨é€²è¡Œåƒæ•¸æ›´æ–°ä¹‹å‰ï¼Œéœ€è¦å…ˆå°‡æ¢¯åº¦æ¸…é›¶ï¼Œä»¥é¿å…æ¢¯åº¦çš„ç´¯ç©å½±éŸ¿ä¸‹ä¸€å€‹batchçš„è¨ˆç®—ã€‚\n","\n","ç¸½çµèµ·ä¾†ï¼Œé€™ä¸€æ®µç¨‹å¼ç¢¼çš„ä½œç”¨æ˜¯åŸ·è¡Œåå‘å‚³æ’­ï¼Œè¨ˆç®—æ¢¯åº¦ä¸¦æ›´æ–°æ¨¡å‹çš„åƒæ•¸ã€‚åŒæ™‚ï¼Œé€šéæ¢¯åº¦è£å‰ªã€å­¸ç¿’ç‡èª¿æ•´å’Œæ¢¯åº¦æ¸…é›¶ç­‰æ“ä½œï¼Œç¢ºä¿è¨“ç·´éç¨‹çš„ç©©å®šå’Œæ­£ç¢ºé€²è¡Œã€‚\n","\n","è®“æˆ‘å€‘å¯«å¦ä¸€å€‹å‡½æ•¸ï¼Œå¹«åŠ©æˆ‘å€‘åœ¨çµ¦å®šçš„æ•¸æ“šåŠ è¼‰å™¨ä¸Šè©•ä¼°æ¨¡å‹ï¼š"],"metadata":{"id":"z9zf0OI7DAQw"}},{"cell_type":"code","source":["def eval_model_gpu(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"k_rmFFhYDCBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model_cpu(model, data_loader, loss_fn, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"]\n","      attention_mask = d[\"attention_mask\"]\n","      targets = d[\"targets\"]\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"F_MQXf3F_lf-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ä¸‹é¢é–‹å§‹è¨“ç·´æ¨¡å‹ä½†è¦è²·è³‡æº"],"metadata":{"id":"Hggf7zNDBv2-"}},{"cell_type":"code","source":["from collections import defaultdict"],"metadata":{"id":"uaM5kdKGERIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time"],"metadata":{"id":"qSS37zP3HiYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","start_time = time.time()\n","\n","history = defaultdict(list)\n","best_accuracy = 0\n","\n","for epoch in range(EPOCHS):\n","\n","  print(f'Epoch {epoch + 1}/{EPOCHS}')\n","  print('-' * 10)\n","\n","  train_acc, train_loss = train_epoch_gpu(\n","    model,\n","    train_data_loader,    \n","    loss_fn, \n","    optimizer, \n","    device, \n","    scheduler, \n","    len(df_train)\n","  )\n","\n","  print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","  val_acc, val_loss = eval_model_gpu(\n","    model,\n","    val_data_loader,\n","    loss_fn, \n","    device, \n","    len(df_val)\n","  )\n","\n","  print(f'Val   loss {val_loss} accuracy {val_acc}')\n","  print()\n","\n","  history['train_acc'].append(train_acc)\n","  history['train_loss'].append(train_loss)\n","  history['val_acc'].append(val_acc)\n","  history['val_loss'].append(val_loss)\n","\n","  if val_acc > best_accuracy:\n","    torch.save(model.state_dict(), 'best_model_state.bin')\n","    best_accuracy = val_acc\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","print(\"Execution time:\", execution_time)"],"metadata":{"id":"2HQcg-onD6Bs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e132d12d-67bd-49b7-80fc-4cf49b1599f1","executionInfo":{"status":"ok","timestamp":1685285503265,"user_tz":-480,"elapsed":494059,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.8306024580930187 accuracy 0.5788888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.7431705338614327 accuracy 0.67\n","\n","Epoch 2/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.7509292379944725 accuracy 0.6611111111111111\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8325371359075818 accuracy 0.65\n","\n","Epoch 3/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.7419162804046563 accuracy 0.6877777777777778\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8338071193013873 accuracy 0.66\n","\n","Epoch 4/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.6831925337293506 accuracy 0.7238888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9800507852009365 accuracy 0.61\n","\n","Epoch 5/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.6280802348546223 accuracy 0.7627777777777778\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8845466205051967 accuracy 0.64\n","\n","Epoch 6/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.5912187125830524 accuracy 0.7955555555555556\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9260453837258475 accuracy 0.61\n","\n","Epoch 7/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.546031499462845 accuracy 0.8138888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8780410630362374 accuracy 0.67\n","\n","Epoch 8/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.5174083810596339 accuracy 0.8372222222222222\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 1.0382854385035378 accuracy 0.63\n","\n","Epoch 9/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.49231906169283707 accuracy 0.8472222222222222\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 1.1350161858967371 accuracy 0.6\n","\n","Epoch 10/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.49059419986684766 accuracy 0.85\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9531845663275037 accuracy 0.65\n","\n","Execution time: 494.1372413635254\n"]}]},{"cell_type":"code","source":["history['train_acc']"],"metadata":{"id":"GHujWGi7hpMr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503266,"user_tz":-480,"elapsed":44,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"ba356a86-99e4-4dfe-bb8f-c2015fc7ba94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(0.5789, device='cuda:0', dtype=torch.float64),\n"," tensor(0.6611, device='cuda:0', dtype=torch.float64),\n"," tensor(0.6878, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7239, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7628, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7956, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8139, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8372, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8472, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8500, device='cuda:0', dtype=torch.float64)]"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["train_acc = [history['train_acc'][i].tolist() for i in range(10)]\n","train_acc"],"metadata":{"id":"n4SBUcf-efrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503268,"user_tz":-480,"elapsed":38,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"7a71fa40-4a4f-4eab-abb0-4bb832d8e9a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5788888888888889,\n"," 0.6611111111111111,\n"," 0.6877777777777778,\n"," 0.7238888888888889,\n"," 0.7627777777777778,\n"," 0.7955555555555556,\n"," 0.8138888888888889,\n"," 0.8372222222222222,\n"," 0.8472222222222222,\n"," 0.85]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["val_acc = [history['val_acc'][i].tolist() for i in range(10)]\n","val_acc"],"metadata":{"id":"S8FZLMhehwqY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503270,"user_tz":-480,"elapsed":37,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"688bf39e-17b6-4471-b243-ff0062299ffa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.67, 0.65, 0.66, 0.61, 0.64, 0.61, 0.67, 0.63, 0.6, 0.65]"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["æœƒå„²å­˜æœ€ä½³æ¨¡å‹çš„ç‹€æ…‹ï¼Œè©²ç‹€æ…‹ç”±æœ€é«˜æº–ç¢ºåº¦è¡¨ç¤ºã€‚"],"metadata":{"id":"u9QNlJ3-EZNE"}},{"cell_type":"code","source":["# ç•«åœ–çœ‹çµæœ\n","plt.plot(train_acc, label='train accuracy')\n","plt.plot(val_acc, label='validation accuracy')\n","\n","plt.title('Training history')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.ylim([0, 1]);"],"metadata":{"id":"e2ee4yfeEybc","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"ok","timestamp":1685285503271,"user_tz":-480,"elapsed":34,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"45b59b7f-e582-4828-c8c1-bec422cf7961"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"c3KfI8EnFKct"}},{"cell_type":"code","source":["test_acc, _ = eval_model_gpu(\n","  model,\n","  test_data_loader,\n","  loss_fn,\n","  device,\n","  len(df_test)\n",")\n","\n","test_acc.item()"],"metadata":{"id":"a0wfA7o9FBcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285504734,"user_tz":-480,"elapsed":1479,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"84fb3557-4509-4f33-d854-eb571f4c92d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.68"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# using gpu\n","def get_predictions(model, data_loader):\n","  model = model.eval()\n","  \n","  content_texts = []\n","  predictions = []\n","  prediction_probs = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","\n","      texts = d[\"content_text\"]\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","      print(preds)\n","      \n","\n","      probs = F.softmax(outputs, dim=1)\n","\n","      content_texts.extend(texts)\n","      predictions.extend(preds)\n","      prediction_probs.extend(probs)\n","      real_values.extend(targets)\n","\n","  predictions = torch.stack(predictions).cpu()\n","  prediction_probs = torch.stack(prediction_probs).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return content_texts, predictions, prediction_probs, real_values"],"metadata":{"id":"lDtiSSpQFzqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_content_texts, y_pred, y_pred_probs, y_test = get_predictions(\n","  model,\n","  test_data_loader\n",")"],"metadata":{"id":"w4s50rEoIzmp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506124,"user_tz":-480,"elapsed":1410,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"5fdc437b-1209-4bcd-a833-cd71531facf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","print(classification_report(y_test, y_pred, target_names=class_names))"],"metadata":{"id":"mLiqD-05JM0Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506124,"user_tz":-480,"elapsed":23,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"abc62170-0f12-4ebb-d51c-851a77f18020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           N       0.00      0.00      0.00         8\n","           M       0.72      0.73      0.73        56\n","           P       0.63      0.75      0.68        36\n","\n","    accuracy                           0.68       100\n","   macro avg       0.45      0.49      0.47       100\n","weighted avg       0.63      0.68      0.65       100\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["def show_confusion_matrix(confusion_matrix):\n","  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n","  plt.ylabel('True sentiment')\n","  plt.xlabel('Predicted sentiment');\n","\n","cm = confusion_matrix(y_test, y_pred)\n","df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n","show_confusion_matrix(df_cm)"],"metadata":{"id":"osPpl4-YJXDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506125,"user_tz":-480,"elapsed":19,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"f385193c-cdf1-4a71-9a3d-0e2106cc281e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAhAAAAG1CAYAAACoOc1JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+Z0lEQVR4nO3dfVxUZf7/8feAMKIIKipgircJmmKmrqLlvaK1pUmpaXm7loZWot1QmWIWVrtrtaW23ahZrq2ZlTfpN0s0NzLDSO2GxDCzvMkbULwZFM7vD39NTppxbI4zHF7PfZzHw7lm5pzP8J1vvPlc1znHYRiGIQAAABMCfF0AAAAoewgQAADANAIEAAAwjQABAABMI0AAAADTCBAAAMA0AgQAADCNAAEAAEwjQAAAANMq+LoAbzp52tcVwN/k7T/m6xLgR+pEhPi6BPiRKk7r/4YOaTXOK/s58flzXtmPN9kqQAAA4Fcc9m302/eTAQAAy9CBAADAKg6HryuwDAECAACrMIUBAADKohkzZsjhcOiee+5xj508eVLJycmKiIhQaGiokpKStG/fPlP7JUAAAGAVh8M720XatGmTXnjhBcXHx3uMT5gwQcuWLdPixYu1bt06/fTTT+rfv7+pfRMgAACwiiPAO9tFKCws1JAhQ/Tiiy+qWrVq7vGCggK9/PLL+uc//6lu3bqpdevWmjt3rj7++GN98sknpd4/AQIAAD/ncrl05MgRj83lcl3wPcnJybruuuvUo0cPj/GsrCydOnXKYzwuLk4xMTHKzMwsdU0ECAAArOKlKYz09HSFh4d7bOnp6b972EWLFmnz5s3nfc3evXsVHBysqlWreoxHRkZq7969pf5onIUBAIBVvHQWRmpqqlJSUjzGnE7neV/7ww8/6O6779b777+vihUreuX450OAAADAzzmdzt8NDL+VlZWl/fv366qrrnKPFRcXa/369Xruuee0evVqFRUVKT8/36MLsW/fPkVFRZW6JgIEAABW8cGFpLp3766tW7d6jI0YMUJxcXG6//77VbduXQUFBemDDz5QUlKSJCknJ0e7du1SQkJCqY9DgAAAwCo+uJBUlSpV1Lx5c4+xypUrKyIiwj0+atQopaSkqHr16goLC9P48eOVkJCg9u3bl/o4BAgAAKzip5eynjlzpgICApSUlCSXy6XExETNmjXL1D4chmEYFtV3yXE7b/wWt/PG2bidN852SW7n3fEhr+znxP8e88p+vIkOBAAAVrHxvTAIEAAAWMVPpzC8wb7RCAAAWIYOBAAAVmEKAwAAmGbjAGHfTwYAACxDBwIAAKsE2HcRJQECAACrMIUBAADwKzoQAABYxcbXgSBAAABgFRtPYRAgAACwio07EPaNRgAAwDJ0IAAAsApTGAAAwDSmMAAAAH5FBwIAAKswhQEAAExjCgMAAOBXdCAAALAKUxgAAMA0pjAAAAB+RQcCAACrMIUBAABMI0AAAADTWAMBAADwKzoQAABYhSkMAABgGlMYAAAAv6IDAQCAVZjCAAAApjGFAQAA8Cs6EAAAWMRh4w4EAQIAAIvYOUAwhQEAgI3Mnj1b8fHxCgsLU1hYmBISEvTee++5n+/SpYscDofHNmbMGNPHoQMBAIBVfNCAqFOnjmbMmKHLL79chmFo/vz56tu3rz7//HNdccUVkqTRo0dr2rRp7vdUqlTJ9HEIEAAAWMQXUxjXX3+9x+PHHntMs2fP1ieffOIOEJUqVVJUVNSfOg5TGAAAWOS3UwUXu7lcLh05csRjc7lcf3j84uJiLVq0SMeOHVNCQoJ7/PXXX1eNGjXUvHlzpaam6vjx46Y/GwECAAA/l56ervDwcI8tPT39d1+/detWhYaGyul0asyYMVq6dKmaNWsmSRo8eLBee+01rV27VqmpqVqwYIFuvfVW0zU5DMMwLvoT+ZmTp31dAfxN3v5jvi4BfqRORIivS4AfqeK0/m/osEGvemU/P88feE7Hwel0yul0nvf1RUVF2rVrlwoKCvTmm2/qpZde0rp169wh4mwffvihunfvrtzcXDVq1KjUNflFB2L48OFyOByaMWOGx/jbb79t61NgrLBo4evq07Ob2rZqoSGDbtbWLVt8XRJ8YPSg69Sv61XnbC88/ft/scDeNn+2SRPGjVXv7p3UJr6pMj5c4+uSygVvTWE4nU73WRW/bL8XHiQpODhYjRs3VuvWrZWenq6WLVvqmWeeOe9r27VrJ0nKzc019dn8IkBIUsWKFfXEE0/o8OHDvi6lzFr13kr9/cl03XFnshYtXqrY2DiNvWOUDh486OvScIn9fc5rmrvk/9xb2t9nS5I6dOnp48rgKydOnNDlsbG6/8HJvi4FPlBSUvK7ayays7MlSdHR0ab26TdnYfTo0UO5ublKT0/Xk08+6etyyqQF8+eq/00D1O/GJEnSw1PStH59ht5+a4lGjb7dx9XhUgqvWs3j8ZKFcxVVu46at2zto4rgax2v6aSO13TydRnljw+a6KmpqerTp49iYmJ09OhRLVy4UBkZGVq9erV27NihhQsX6tprr1VERIS2bNmiCRMmqFOnToqPjzd1HL/pQAQGBurxxx/Xv/71L+3evdvX5ZQ5p4qK9PVXX6p9Qgf3WEBAgNq376AtX3zuw8rga6dOndK6999T9z59mRIELjFvTWGYsX//fg0dOlSxsbHq3r27Nm3apNWrV6tnz54KDg7WmjVr1KtXL8XFxWnixIlKSkrSsmXLTH82v+lASNKNN96oK6+8UlOmTNHLL7/s63LKlMP5h1VcXKyIiAiP8YiICOXlfeejquAPNm5Yq2OFR9W99w2+LgXAJXCh359169bVunXrvHIcvwoQkvTEE0+oW7dumjRp0gVf53K5zpnPMQJ/f0UqUF6tWfm2rmrXQdVr1PR1KUC5Y+eun99MYfyiU6dOSkxMVGpq6gVfd75zYp96ovyuMK9WtZoCAwPPWTB58OBB1ahRw0dVwdf27/1JWzZ/qp7X3ujrUoByyRdTGJeK3wUISZoxY4aWLVumzMzM331NamqqCgoKPLZ7779w6LCzoOBgNW12hTZ+8uvPrKSkRBs3Ziq+ZSsfVgZf+mDVuwqvWl1tEq72dSkAbMbvpjAkqUWLFhoyZIieffbZ333N+S6gUd4vJHXbsBGa/OD9uuKK5mreIl6vLZivEydOqN+N/X1dGnygpKREH656V10T/6rAQL/8f3VcQsePH9MPu3a5H//4427lfPO1wsPDFRVd24eV2Zu/dg+8wW//qzJt2jS98cYbvi6jTOnd51odPnRIs557VgcO/KzYuKaa9cJLimAKo1z6Imujft63V9379PV1KfADX335pcaMGuZ+PPOpJyRJf72hn6ZOL7/Tv5azb37gUtawNy5ljbNxKWuc7VJcyrrG8EVe2c+BeYO8sh9v8ss1EAAAwL/57RQGAABlHWsgAACAaXYOEExhAAAA0+hAAABgFfs2IAgQAABYhSkMAACAs9CBAADAInbuQBAgAACwiJ0DBFMYAADANDoQAABYxM4dCAIEAABWsW9+IEAAAGAVO3cgWAMBAABMowMBAIBF7NyBIEAAAGAROwcIpjAAAIBpdCAAALCKfRsQBAgAAKzCFAYAAMBZ6EAAAGARO3cgCBAAAFjEzgGCKQwAAGAaHQgAACxi5w4EAQIAAKvYNz8QIAAAsIqdOxCsgQAAAKbRgQAAwCJ0IAAAgGkOh3c2M2bPnq34+HiFhYUpLCxMCQkJeu+999zPnzx5UsnJyYqIiFBoaKiSkpK0b98+05+NAAEAgI3UqVNHM2bMUFZWlj777DN169ZNffv21ZdffilJmjBhgpYtW6bFixdr3bp1+umnn9S/f3/Tx3EYhmF4u3hfOXna1xXA3+TtP+brEuBH6kSE+LoE+JEqTuv/hr783lVe2c/2p3r/qfdXr15dTz31lG666SbVrFlTCxcu1E033SRJ+uabb9S0aVNlZmaqffv2pd4nayAAALCIt5ZAuFwuuVwujzGn0ymn03nB9xUXF2vx4sU6duyYEhISlJWVpVOnTqlHjx7u18TFxSkmJsZ0gGAKAwAAP5eenq7w8HCPLT09/Xdfv3XrVoWGhsrpdGrMmDFaunSpmjVrpr179yo4OFhVq1b1eH1kZKT27t1rqiY6EAAAWMRbZ2GkpqYqJSXFY+xC3YfY2FhlZ2eroKBAb775poYNG6Z169Z5pZZfECAAALCIt6YwSjNdcbbg4GA1btxYktS6dWtt2rRJzzzzjAYOHKiioiLl5+d7dCH27dunqKgoUzUxhQEAgM2VlJTI5XKpdevWCgoK0gcffOB+LicnR7t27VJCQoKpfdKBAADAIgEBl/5CUqmpqerTp49iYmJ09OhRLVy4UBkZGVq9erXCw8M1atQopaSkqHr16goLC9P48eOVkJBgagGlRIAAAMAyvrgQ5f79+zV06FDt2bNH4eHhio+P1+rVq9WzZ09J0syZMxUQEKCkpCS5XC4lJiZq1qxZpo/DdSBga1wHAmfjOhA426W4DkTzh9/3yn62Te/plf14E2sgAACAaUxhAABgERvfS4sAAQCAVbgbJwAAwFnoQAAAYBE7dyAIEAAAWMTG+YEpDAAAYB4dCAAALMIUBgAAMM3G+YEAAQCAVezcgWANBAAAMI0OBAAAFrFxA4IAAQCAVZjCAAAAOAsdCAAALGLjBgQBAgAAqzCFAQAAcBY6ELC1q66739clwI+88CLfB/xqaJu6lh/Dxg0IAgQAAFZhCgMAAOAsdCAAALCIjRsQBAgAAKxi5ykMAgQAABaxcX5gDQQAADCPDgQAABZhCgMAAJhm5wDBFAYAADCNDgQAABaxcQPCfAdi2rRpOn78+DnjJ06c0LRp07xSFAAAduBwOLyy+SPTASItLU2FhYXnjB8/flxpaWleKQoAAPg301MYhmGcNw198cUXql69uleKAgDADvy0eeAVpQ4Q1apVc7dSmjRp4hEiiouLVVhYqDFjxlhSJAAAZZG/Tj94Q6kDxNNPPy3DMDRy5EilpaUpPDzc/VxwcLDq16+vhIQES4oEAAD+pdQBYtiwYZKkBg0aqEOHDgoKCrKsKAAA7MDGDQjziyg7d+6swMBAffvtt9qwYYPWr1/vsQEAgDMCHA6vbGakp6erbdu2qlKlimrVqqV+/fopJyfH4zVdunQ550wPs8sQTC+i/OSTTzR48GB9//33MgzD4zmHw6Hi4mKzuwQAwJZ80YFYt26dkpOT1bZtW50+fVoPPvigevXqpa+++kqVK1d2v2706NEel1+oVKmSqeOYDhBjxoxRmzZttGLFCkVHR9t6gQgAAGXNqlWrPB7PmzdPtWrVUlZWljp16uQer1SpkqKioi76OKYDxPbt2/Xmm2+qcePGF31QAADKA2/9ke1yueRyuTzGnE6nnE7nH763oKBAks651MLrr7+u1157TVFRUbr++us1efJkU10I02sg2rVrp9zcXLNvAwCg3AlweGdLT09XeHi4x5aenv6Hxy8pKdE999yjjh07qnnz5u7xwYMH67XXXtPatWuVmpqqBQsW6NZbbzX12Ux3IMaPH6+JEydq7969atGixTlnY8THx5vdJQAAuIDU1FSlpKR4jJWm+5CcnKxt27Zpw4YNHuO33367+98tWrRQdHS0unfvrh07dqhRo0alqsl0gEhKSpIkjRw50j3mcDjcV6hkESUAAGd4awqjtNMVZxs3bpyWL1+u9evXq06dOhd8bbt27SRJubm51gWIvLw8s28BAKBc8sV5BoZhaPz48Vq6dKkyMjLUoEGDP3xPdna2JCk6OrrUxzEdIOrVq2f2LQAA4BJJTk7WwoUL9c4776hKlSrau3evJCk8PFwhISHasWOHFi5cqGuvvVYRERHasmWLJkyYoE6dOplahmB6EaUkLViwQB07dlTt2rX1/fffSzpzqet33nnnYnYHAIAtObz0PzNmz56tgoICdenSRdHR0e7tjTfekHTm9hNr1qxRr169FBcXp4kTJyopKUnLli0zdRzTHYjZs2frkUce0T333KPHHnvMveahatWqevrpp9W3b1+zuwQAwJYCfDSFcSF169bVunXr/vRxTHcg/vWvf+nFF1/UQw89pMDAQPd4mzZttHXr1j9dEAAA8H8XtYiyVatW54w7nU4dO3bMK0UBAGAHdr5as+kORIMGDdyrNc+2atUqNW3a1Bs1AQBgCw6HdzZ/ZLoDkZKSouTkZJ08eVKGYejTTz/Vf/7zH6Wnp+ull16yokYAAMoks3fSLEtMB4i//e1vCgkJ0cMPP6zjx49r8ODBql27tp555hkNGjTIihoBAICfMR0gJGnIkCEaMmSIjh8/rsLCQtWqVcvbdQEAUObZuAFxcQHiF5UqVTJ9/3AAAMoLOy+iNB0gDh48qEceeURr167V/v37VVJS4vH8oUOHvFYcAADwT6YDxG233abc3FyNGjVKkZGRtk5XAAD8GXb+FWk6QHz00UfasGGDWrZsaUU9AADYhp3PwjB9HYi4uDidOHHCiloAAEAZYTpAzJo1Sw899JDWrVungwcP6siRIx4bAAA4w+GlzR+ZnsKoWrWqjhw5om7dunmMG4Yhh8PhvrkWAADlnZ3XCZoOEEOGDFFQUJAWLlzIIkoAAMop0wFi27Zt+vzzzxUbG2tFPQAA2IYvbud9qZheA9GmTRv98MMPVtQCAICtOBwOr2z+yHQHYvz48br77rt17733qkWLFgoKCvJ4Pj4+3mvFAQBQlvnp736vMB0gBg4cKEkaOXKke8zhcLCIEgCAcsR0gMjLy7OiDgAAbMdfpx+8wXSAqFevnhV1AABgO3ZeRFmqAPHuu++qT58+CgoK0rvvvnvB195www1eKQwAAPivUgWIfv36ae/evapVq5b69ev3u69jDQQAAL8q91MYZ9+y+7e37wYAAOdn3/hwEdeBePXVV+Vyuc4ZLyoq0quvvuqVogAAgH8zHSBGjBihgoKCc8aPHj2qESNGeKUoAADsIMDh8Mrmj0yfhfHL9R5+a/fu3QoPD/dKUQAA2IGf/u73ilIHiFatWrkvqdm9e3dVqPDrW4uLi5WXl6fevXtbUiQAAPAvpQ4Qv5x9kZ2drcTERIWGhrqfCw4OVv369ZWUlOT1AgEAKKvK/VkYkjRlyhRJUv369TVw4EBVrFjxTx98+PDhmj9/vu644w7NmTPH47nk5GTNmjVLw4YN07x58/70scqLRQtf1/y5L+vAgZ/VJDZODzw4WS24P0m5M2lETz16V1899/pa3fv3JZKkkf07amCfNroyro7CQkMUdc29Kig84eNKYZVdX29R5or/am/edhXmH9RNE9IU26aj+/llc57Ulo/+z+M9DePb6Jb7Z1zqUm3NxvnB/BqIYcOGSTpz1sX+/fvPOa0zJibG1P7q1q2rRYsWaebMmQoJCZEknTx5UgsXLjS9r/Ju1Xsr9fcn0/XwlDS1aNFSry+Yr7F3jNI7y1cpIiLC1+XhEmndLEajkjpqy7e7PcYrVQzS+x9/pfc//kqP3tXXR9XhUilynVRkTEO17NxbS56eet7XNIxvq+vvuNf9OPA3N0fEn+evCyC9wXSA2L59u0aOHKmPP/7YY/xib6Z11VVXaceOHXrrrbc0ZMgQSdJbb72lmJgYNWjQwGx55dqC+XPV/6YB6nfjmamkh6ekaf36DL391hKNGn27j6vDpVA5JFhzHx+uOx/9jx74m+eapOcWZkiSrml9uQ8qw6XW+Mq/qPGVf7ngayoEBSm0avVLVBHsxnSAGD58uCpUqKDly5crOjraK/M7I0eO1Ny5c90B4pVXXtGIESOUkZHxp/ddXpwqKtLXX32pUaPvcI8FBASoffsO2vLF5z6sDJfS06kDteqjbVq7MeecAAH81vdff6GZY29Sxcqhqt/sSnW+eYQqVeFsOm+ycQPCfIDIzs5WVlaW4uLivFbErbfeqtTUVH3//feSpP/9739atGgRAcKEw/mHVVxcfM5URUREhPLyvvNRVbiUbk5srSvj6urqW5/0dSkoAxq2bKvYtleras0oHd6/RxlvvKxFTz6o4WnPKiAg0Nfl2QaLKM/SrFkzHThwwKtF1KxZU9ddd53mzZsnwzB03XXXqUaNGhd8j8vlOueKmEagU06n06u1AWVBnciqeureJP117HNyFZ32dTkoA65I6Or+d62YhqoV00CzJgzV9199oQbNr/JhZSgrTF+J8oknntB9992njIwMHTx4UEeOHPHYLtbIkSM1b948zZ8/XyNHjvzD16enpys8PNxje+qJ9Is+fllXrWo1BQYG6uDBgx7jBw8e/MMwhrKvVdMYRUaEKXPh/Tq66Rkd3fSMOrW5XHfe0llHNz2jADvfUxheUa1WbVWqEq7D+37ydSm2EuClzYz09HS1bdtWVapUcd8EMycnx+M1J0+eVHJysiIiIhQaGqqkpCTt27fP1HFMdyB69OghSerevbvH+MUuovxF7969VVRUJIfDocTExD98fWpqqlJSUjxrCCy/3Yeg4GA1bXaFNn6SqW7dz/zfqKSkRBs3ZmrQLbf6uDpYbe2nOWp902MeY/9Ou1U5efv0j3nvq6TE8FFlKCuOHPxZxwuPsKjSy3wxhbFu3TolJyerbdu2On36tB588EH16tVLX331lSpXrixJmjBhglasWKHFixcrPDxc48aNU//+/fW///2v1McxHSDWrl1r9i2lEhgYqK+//tr97z/idJ47XXGynHdubxs2QpMfvF9XXNFczVvE67UF83XixAn1u7G/r0uDxQqPu/TVjj0eY8dOFOlQwTH3eGREFUVGhKlRzJmOVPPLa+vosZP6Ye9hHT5y/JLXDGsVnTyhQ3t/dD/O/3mP9u7MVUhoFYWEhumjt15VXNtrVLlqdR3e95M+/M+Lqh5ZWw3j2/iwanjDqlWrPB7PmzdPtWrVUlZWljp16qSCggK9/PLLWrhwobp16yZJmjt3rpo2bapPPvlE7du3L9VxTAeIzp07m31LqYWFhVm27/Kgd59rdfjQIc167lkdOPCzYuOaatYLLymCKQxI+ttN1+jhMde6H695ZYIkafQjC/Taso2+KgsW2fNdjl57bJL78ZrXzlysL/6aXuo98m7t3/Wdtnz0vk4eK1SVahFq0KK1Ot88QhWCgn1Vsi15a/bwfOv+zveH9Pn8cgPM6tXPdJeysrJ06tQp94yCJMXFxSkmJkaZmZmlDhAOwzBM9zY/+ugjvfDCC/ruu++0ePFiXXbZZVqwYIEaNGigq6++2uzuvKa8dyBwrmptx/m6BPiRF16839clwI8MbVPX8mOkvPuNV/YTtnmR0tLSPMamTJmiqVOnXvB9JSUluuGGG5Sfn68NGzZIkhYuXKgRI0acE0j+8pe/qGvXrnriiSdKVZPpRZRLlixRYmKiQkJCtHnzZncBBQUFevzxx83uDgAA/IHU1FQVFBR4bKmpqX/4vuTkZG3btk2LFi3yek2mA8T06dM1Z84cvfjiiwo667KnHTt21ObNm71aHAAAZdkvd7H+s5vT6VRYWJjH9kfTF+PGjdPy5cu1du1a1alTxz0eFRWloqIi5efne7x+3759ioqKKvVnMx0gcnJy1KlTp3PGw8PDzykGAIDyLMDhnc0MwzA0btw4LV26VB9++OE5t4Vo3bq1goKC9MEHH7jHcnJytGvXLiUkJJT6OKYXUUZFRSk3N1f169f3GN+wYYMaNmxodncAANiWLy5EmZycrIULF+qdd95RlSpVtHfvXkln/tAPCQlReHi4Ro0apZSUFFWvXl1hYWEaP368EhISSr2AUrqIADF69GjdfffdeuWVV+RwOPTTTz8pMzNTkyZN0uTJk83uDgAAeNHs2bMlSV26dPEYnzt3roYPHy5JmjlzpgICApSUlCSXy6XExETNmjXL1HFMB4gHHnhAJSUl6t69u44fP65OnTrJ6XRq0qRJGj9+vNndAQBgW764nXdpTq6sWLGinn/+eT3//PMXfRzTAcLhcOihhx7Svffeq9zcXBUWFqpZs2YKDQ296CIAALAj0wsNy5CL/mzBwcFq1qyZ4uLitGbNGvdVJAEAgP2ZDhADBgzQc889J0k6ceKE2rZtqwEDBig+Pl5LlizxeoEAAJRVDod3Nn9kOkCsX79e11xzjSRp6dKlKikpUX5+vp599llNnz7d6wUCAFBWBTgcXtn8kekAUVBQ4L6e9qpVq5SUlKRKlSrpuuuu0/bt271eIAAA8D+mA0TdunWVmZmpY8eOadWqVerVq5ck6fDhw6pYsaLXCwQAoKyy8xSG6bMw7rnnHg0ZMkShoaGqV6+e+zzT9evXq0WLFt6uDwCAMstbd+P0R6YDxJ133ql27dpp165d6tmzpwICzjQxGjZsyBoIAADKCdMBQjpzHe3WrVt7jF133XVeKQgAALvw1wWQ3nBRAQIAAPwxG+cHAgQAAFax8xoIO19lEwAAWIQOBAAAFnHIvi2Ii+pAfPTRR7r11luVkJCgH3/8UZK0YMECbdiwwavFAQBQlgU4vLP5I9MBYsmSJUpMTFRISIg+//xzuVwuSWeuUPn44497vUAAAOB/TAeI6dOna86cOXrxxRcVFBTkHu/YsaM2b97s1eIAACjL7NyBML0GIicnR506dTpnPDw8XPn5+d6oCQAAW3DY+DxO0x2IqKgo5ebmnjO+YcMGNWzY0CtFAQAA/2Y6QIwePVp33323Nm7cKIfDoZ9++kmvv/66Jk2apLFjx1pRIwAAZRJTGGd54IEHVFJSou7du+v48ePq1KmTnE6nJk2apPHjx1tRIwAAZZKNZzDMBwiHw6GHHnpI9957r3Jzc1VYWKhmzZopNDTUivoAAIAfuugLSQUHB6tZs2berAUAAFvhZlpn6dq16wVXlX744Yd/qiAAAOzCX9cveIPpAHHllVd6PD516pSys7O1bds2DRs2zFt1AQBQ5tm4AWE+QMycOfO841OnTlVhYeGfLggAAPg/r92N89Zbb9Urr7zird0BAFDmBcjhlc0fee1unJmZmapYsaK3dgcAQJnHFMZZ+vfv7/HYMAzt2bNHn332mSZPnuy1wgAAgP8yHSDCw8M9HgcEBCg2NlbTpk1Tr169vFYYAABlHWdh/H/FxcUaMWKEWrRooWrVqllVEwAAtmDn60CYWkQZGBioXr16cddNAADKOdNnYTRv3lzfffedFbUAAGArDod3Nn9kOkBMnz5dkyZN0vLly7Vnzx4dOXLEYwMAAGcEOBxe2fxRqddATJs2TRMnTtS1114rSbrhhhs8LmltGIYcDoeKi4u9XyUAAPArpQ4QaWlpGjNmjNauXWtlPQAA2Iavmgfr16/XU089paysLO3Zs0dLly5Vv3793M8PHz5c8+fP93hPYmKiVq1aVepjlDpAGIYhSercuXOpdw4AQHnmtcs9m3Ts2DG1bNlSI0eOPOf6Tb/o3bu35s6d637sdDpNHcPUaZwXugsnAADw5Kvfm3369FGfPn0u+Bqn06moqKiLPoapANGkSZM//GEcOnTooosBAADncrlccrlcHmNOp9N01+BsGRkZqlWrlqpVq6Zu3bpp+vTpioiIKPX7TQWItLS0c65ECQAAzs9b/Yf09HSlpaV5jE2ZMkVTp069qP317t1b/fv3V4MGDbRjxw49+OCD6tOnjzIzMxUYGFiqfZgKEIMGDVKtWrUuqlgAAMobb52CmZqaqpSUFI+xP9N9GDRokPvfLVq0UHx8vBo1aqSMjAx17969VPso9foO1j8AAOAbTqdTYWFhHtufCRC/1bBhQ9WoUUO5ubmlfo/pszAAAEDplJU/vXfv3q2DBw8qOjq61O8pdYAoKSm5qKIAACivfNW8Lyws9Ogm5OXlKTs7W9WrV1f16tWVlpampKQkRUVFaceOHbrvvvvUuHFjJSYmlvoYpm/nDQAA/Ntnn32mrl27uh//sn5i2LBhmj17trZs2aL58+crPz9ftWvXVq9evfToo4+amhYhQAAAYBFfrR/s0qXLBZcerF69+k8fgwABAIBFfHUlykvBzp8NAABYhA4EAAAWsfMlEAgQAABYxL7xgQABAIBl6EAAZdSGpY/7ugT4kfH/zfZ1CfAjQ9vU9XUJZRoBAgAAi9j5TAUCBAAAFrHzFIadwxEAALAIHQgAACxi3/4DAQIAAMvYeAaDKQwAAGAeHQgAACwSYONJDAIEAAAWYQoDAADgLHQgAACwiIMpDAAAYJadpzAIEAAAWMTOiyhZAwEAAEyjAwEAgEWYwgAAAKbZOUAwhQEAAEyjAwEAgEU4jRMAAJgWYN/8wBQGAAAwjw4EAAAWYQoDAACYxlkYAAAAZ6EDAQCARZjCAAAAptn5LAwCBAAAFrFzB4I1EAAAwDQ6EAAAWMTOZ2EQIAAAsIiN8wNTGAAA2M369et1/fXXq3bt2nI4HHr77bc9njcMQ4888oiio6MVEhKiHj16aPv27aaOQYAAAMAiAQ6HVzazjh07ppYtW+r5558/7/NPPvmknn32Wc2ZM0cbN25U5cqVlZiYqJMnT5b6GExhAABgEV9NYfTp00d9+vQ573OGYejpp5/Www8/rL59+0qSXn31VUVGRurtt9/WoEGDSnUMOhAAAPg5l8ulI0eOeGwul+ui9pWXl6e9e/eqR48e7rHw8HC1a9dOmZmZpd4PAQIAAKs4vLOlp6crPDzcY0tPT7+okvbu3StJioyM9BiPjIx0P1caTGEAAGARb11IKjU1VSkpKR5jTqfTK/u+WAQIAAD8nNPp9FpgiIqKkiTt27dP0dHR7vF9+/bpyiuvLPV+mMIAAMAiDod3Nm9q0KCBoqKi9MEHH7jHjhw5oo0bNyohIaHU+6EDAQCARXx1FkZhYaFyc3Pdj/Py8pSdna3q1asrJiZG99xzj6ZPn67LL79cDRo00OTJk1W7dm3169ev1McgQAAAYBUfJYjPPvtMXbt2dT/+Zf3EsGHDNG/ePN133306duyYbr/9duXn5+vqq6/WqlWrVLFixVIfw2EYhuH1yn3k5GlfVwB/8+XuI74uAX5k/H+zfV0C/MjH93Wy/Bib8gq8sp+2DcK9sh9vogMBAIBF7Hw7bwIEAAAWsfPdODkLAwAAmEYHAgAAi9i4AUGAAADAMjZOEExhAAAA0+hAAABgEc7CAAAApnEWBgAAwFnoQAAAYBEbNyAIEAAAWMbGCYIAAQCARey8iJI1EAAAwDQ6EAAAWMTOZ2EQIAAAsIiN8wNTGAAAwDy/6kAMHz5c8+fPlyQFBQUpJiZGQ4cO1YMPPqgKFfyqVL+1aOHrmj/3ZR048LOaxMbpgQcnq0V8vK/Lgg+cOH5Mi+fP0WcfZ6gg/7DqN2qioWMnqlHsFb4uDRa7rV1ddWlSQzERISo6VaKtPx3RrHV52nXohCQpKsypt8a0O+97H3rnK63NOXApy7U3G7cg/O63cu/evTV37ly5XC6tXLlSycnJCgoKUmpqqq9L83ur3lupvz+ZroenpKlFi5Z6fcF8jb1jlN5ZvkoRERG+Lg+X2Iszp+uHnTs09r40VateUxs+fE+PP5Csp178r6rXqOXr8mChVnXDteTzn/T1nqMKDHBoTKf6evrmFhr8ymc6eapE+4+69NfnMz3e07dltAb/pY4++e6Qj6q2J87CuIScTqeioqJUr149jR07Vj169NC7777r67LKhAXz56r/TQPU78YkNWrcWA9PSVPFihX19ltLfF0aLrEi10l9umGtBv/tLjVtcZWiLqurm267XZG162rNcr4Pdpfy5jat3LZPeQePK/fnY5q+8ltFhVdUXGQVSVKJIR06dspj63x5DX34zQGdOFXi4+pRVvhdgPitkJAQFRUV+boMv3eqqEhff/Wl2id0cI8FBASoffsO2vLF5z6sDL5QXFyskpJiBQUHe4wHO53K+TLbN0XBZyo7AyVJR06eOu/zsZGhahIZqmVb9l7KssoFh8M7mz/y2wBhGIbWrFmj1atXq1u3br4ux+8dzj+s4uLic6YqIiIidOAA85nlTUilyrq8aQstXfiyDh/8WSXFxdrwwUpt/3qr8g/xfShPHJLu6d5IX+wu0HcHjp/3NdfHRynvwDFt++nIpS2uHHB4afNHfrcGYvny5QoNDdWpU6dUUlKiwYMHa+rUqee8zuVyyeVyeYwZgU45nc5LVCng3+68b5pe+Oc0JQ++VgEBgarfOFYduvRS3vZvfF0aLqGJPRurYY3KGvN69nmfD64QoJ5Na2le5veXtjCUeX7Xgejatauys7O1fft2nThxQvPnz1flypXPeV16errCw8M9tqeeSPdBxf6hWtVqCgwM1MGDBz3GDx48qBo1avioKvhSZO06euTv/9Yr76zXv15brun/mq/i06dVK/oyX5eGSySlRyN1bBShcYu26OfC808Fd2tSQxWDAvTetv2XuLpywsYtCL8LEJUrV1bjxo0VExNzwVM3U1NTVVBQ4LHde3/5PVMjKDhYTZtdoY2f/LqyuqSkRBs3Ziq+ZSsfVgZfq1gxRNUiaqjw6BFtyfpErRM6+bokXAIpPRqp8+U1NP6NL7Sn4OTvvu6v8VHakHtQ+SfOvz4Cf47DS//zR343hVFaTue50xUnT/uoGD9x27ARmvzg/briiuZq3iJery2YrxMnTqjfjf19XRp84IvPMiXDUHTdetr3424tfOkZ1a5bX5173eDr0mCxST0bq2fTWrp/6Zc6XlSs6pWDJEmFrmIVnf71LIvLqlbUlXXDNfHNbb4q1fb8dQGkN5TZAIFz9e5zrQ4fOqRZzz2rAwd+VmxcU8164SVFMIVRLp04VqhFc5/XoQP7FVolTG07dtPAEXdyUbZyoH+r2pKkWbe09BifvjJHK7ftcz/+a4so7T/q0qd5hy9pfbAHh2EYhq+L8Jby3oHAub7czapy/Gr8f7N9XQL8yMf3WT+d9+3e85/5YlaTqEpe2Y838acIAABWsfEUht8togQAAP6PDgQAABbx1zMovIEAAQCARex8FgZTGAAAwDQ6EAAAWMTGDQgCBAAAlrFxgmAKAwAAG5k6daocDofHFhcX5/Xj0IEAAMAivjoL44orrtCaNWvcj624Ai0BAgAAi/jqLIwKFSooKirK0mMwhQEAgEV8dTfv7du3q3bt2mrYsKGGDBmiXbt2/dmPcg46EAAA+DmXyyWXy+Uxdr67UktSu3btNG/ePMXGxmrPnj1KS0vTNddco23btqlKlSpeq4kOBAAAVvFSCyI9PV3h4eEeW3p6+nkP2adPH918882Kj49XYmKiVq5cqfz8fP33v//16kejAwEAgEW8tYgyNTVVKSkpHmPn6z6cT9WqVdWkSRPl5uZ6pZZf0IEAAMDPOZ1OhYWFeWylDRCFhYXasWOHoqOjvVoTAQIAAIs4HN7ZzJg0aZLWrVunnTt36uOPP9aNN96owMBA3XLLLV79bExhAABgEV+cxbl7927dcsstOnjwoGrWrKmrr75an3zyiWrWrOnV4xAgAACwkUWLFl2S4xAgAACwiJ1v502AAADAMvZNECyiBAAAptGBAADAIkxhAAAA02ycHwgQAABYxc4dCNZAAAAA0+hAAABgEW/dC8MfESAAALCKffMDUxgAAMA8OhAAAFjExg0IAgQAAFbhLAwAAICz0IEAAMAinIUBAADMs29+IEAAAGAVG+cH1kAAAADz6EAAAGARO5+FQYAAAMAidl5EyRQGAAAwjQ4EAAAWsfMUBh0IAABgGgECAACYxhQGAAAWsfMUBgECAACLcBYGAADAWehAAABgEaYwAACAaTbODwQIAAAsY+MEwRoIAABgGh0IAAAsYuezMAgQAABYxM6LKJnCAAAAptGBAADAIjZuQNCBAADAMg4vbRfh+eefV/369VWxYkW1a9dOn3766Z/6KL9FgAAAwGbeeOMNpaSkaMqUKdq8ebNatmypxMRE7d+/32vHIEAAAGARh5f+Z9Y///lPjR49WiNGjFCzZs00Z84cVapUSa+88orXPhsBAgAAizgc3tnMKCoqUlZWlnr06OEeCwgIUI8ePZSZmem1z8YiSgAA/JzL5ZLL5fIYczqdcjqd57z2wIEDKi4uVmRkpMd4ZGSkvvnmG6/VZKsAUdFWn+biuFwupaenKzU19bxfrPKmdf0wX5fgc3wnfvXxfZ18XYLP8X24tLz1e2nq9HSlpaV5jE2ZMkVTp071zgEugsMwDMNnR4fXHTlyROHh4SooKFBYGL88wXcCnvg+lE1mOhBFRUWqVKmS3nzzTfXr1889PmzYMOXn5+udd97xSk2sgQAAwM85nU6FhYV5bL/XQQoODlbr1q31wQcfuMdKSkr0wQcfKCEhwWs10fQHAMBmUlJSNGzYMLVp00Z/+ctf9PTTT+vYsWMaMWKE145BgAAAwGYGDhyon3/+WY888oj27t2rK6+8UqtWrTpnYeWfQYCwGafTqSlTprA4Cm58J3A2vg/lx7hx4zRu3DjL9s8iSgAAYBqLKAEAgGkECAAAYBoBAgAAmEaAAAAAphEgypgTJ05o9erVvi4DfuTHH39UQUGBr8uAHzl06JCvS0A5QIAoQ0pKSjRr1iz16dNH+fn5vi4HPlZSUqJp06YpNjZWc+bM8XU58APLli1Tly5d1L9/f40dO1abNm3ydUmwMQJEGRIQEKAbb7xRLVu21J133unrcuBjR48e1eLFi1WxYkVt2rRJmzdv9nVJ8JGdO3fq6quv1tChQ9WhQwe1atVKS5cu1YQJE3Ts2DFflwebIkD4se+//14vvPCCvv76a/dYvXr1dO+992rRokXKysryYXXwpeLiYoWHh+vqq69WtWrVVFJSokWLFvm6LPjA4cOHdcMNN2jnzp366aef9Pjjj2vmzJmaNm2a8vLy9MYbb/i6RNgUAcJPHT58WD169NDYsWPVp08fLVu2TIcOHVJgYKB69uypxMRE3X777b4uE5fIzp079eijjyozM1OSZBiGDMNQXFycEhMTVatWLW3cuJH1MeVQtWrVNHDgQF1++eX69NNP3eOdOnXSwYMHFRDAf+ZhDb5ZfqpatWoaOXKk2rZtq5CQED311FPq27evvv32W9WsWVOpqanatm2b5s+f7+tSYbHDhw+rd+/emjJligYNGqSsrCydOnVKDodDJ06c0J49e/TQQw9JkhYvXkzLuhxKTk6W0+nUiy++6B7LzMxUeHi4mjZt6sPKYGcECD82duxYXXbZZWrdurWee+45BQYG6q9//avS0tLUoEED3XfffUpJSfF1mbBYtWrVNHToUHXr1k2hoaH6xz/+oenTp0uSbr75ZmVmZqpSpUoaMGCAtm7dqjfffNPHFeNSq1q1qkaOHKm8vDzNnDlTAwYM0Lhx4zR9+nS1a9fO1+XBpggQfqxq1aoaOHCgvvnmG/3www/KyMjQ5MmT9dJLL2ngwIEKCwtTQECAHnvsMV+XCouNHTtWYWFhatGihW6++WYtWLBA06dP1/bt29WlSxft2rVLt9xyi6Kjo7V8+XLt2rXL1yXjErvxxht12WWX6YEHHtDJkye1Y8cOjR49WtKZKS/A2wgQfq5///5q1KiRZs+erR9//FG33XabVqxYobZt22rmzJk6ePCgJk+erAMHDvi6VFioWrVqGjBggHbu3Kng4GC99dZbys7O1owZM7RixQrl5+erevXqGjRokL777ju98MILvi4Zl1hQUJDuu+8+xcfHq0OHDoqKinIHB4fD4ePqYEcECD8XFBSkiRMn6tChQ5o7d64kKT4+Xs8884xeeuklXXPNNWrfvr0qVKjAXxk2l5SUpHr16mnWrFlq0qSJnn32WTVu3FhHjx7V3r17JUmDBg1SfHy8YmNjfVwtfKF169bq2LGj/u///k9ffPGFHA6HiouLfV0WbIrbeZcBhmFowoQJ2rJli55++mnFx8fLMAw5HA4VFRUpODjY1yXiEvn0009111136YYbbtCDDz4owzD03XffqVGjRnwnIEnavXu3brnlFjVo0ECvvvqqr8uBjdGBKAMcDocmTpyoU6dO6e9//7t7TBK/KMqZtm3bqn379lqzZo2ys7PlcDjUqFEjlZSU8J2AJKlOnTrq16+f2rRpQ1cSlqIDUYb84x//UFBQkMaPH8+cZjn2ww8/aPDgwfyFid/1SzcKsFIFXxeA0ktJSeE/ClDdunXVr18/BQUF8YsC58V3ApcCHQigDCI4APA11kAAZRDhAYCvESAAAIBpBAgAAGAaAQIAAJhGgAAAAKYRIAAAgGkECAAAYBoBAvgThg8frn79+rkfd+nSRffcc88lryMjI0MOh0P5+fmX/NgXsnPnTjkcDmVnZ/u6FABeRoCA7QwfPlwOh0MOh0PBwcFq3Lixpk2bptOnT1t+7LfeekuPPvpoqV7rr7/0L9Zvw5R05qqZe/bsUfPmzX1T1FmmTp2qK6+80tdlALbBpaxhS71799bcuXPlcrm0cuVKJScnKygoSKmpqee81pt3r6xevbpX9mMXgYGBioqK8nUZACxABwK25HQ6FRUVpXr16mns2LHq0aOH3n33XUm//qX82GOPqXbt2oqNjZV05iZVAwYMUNWqVVW9enX17dtXO3fudO+zuLhYKSkpqlq1qiIiInTfffedc7fD305huFwu3X///apbt66cTqcaN26sl19+WTt37lTXrl0lSdWqVZPD4dDw4cMlSSUlJUpPT1eDBg0UEhKili1b6s033/Q4zsqVK9WkSROFhISoa9euHnWej2EYmjp1qmJiYuR0OlW7dm3dddddHnVOmjRJl112mSpXrqx27dopIyPD/fy8efNUtWpVrV69Wk2bNlVoaKh69+6tPXv2SDrz1/38+fP1zjvvuLs/GRkZ50xh/NJ1Wb16tVq1aqWQkBB169ZN+/fv13vvvaemTZsqLCxMgwcP1vHjx93H/6OfyS/7/eCDD9SmTRtVqlRJHTp0UE5Ojrv+tLQ0ffHFF+765s2bd8GfGYA/YAA2M2zYMKNv374eYzfccINx1VVXuZ8PDQ01brvtNmPbtm3Gtm3bjKKiIqNp06bGyJEjjS1bthhfffWVMXjwYCM2NtZwuVyGYRjGE088YVSrVs1YsmSJ8dVXXxmjRo0yqlSp4nGszp07G3fffbf78YABA4y6desab731lrFjxw5jzZo1xqJFi4zTp08bS5YsMSQZOTk5xp49e4z8/HzDMAxj+vTpRlxcnLFq1Spjx44dxty5cw2n02lkZGQYhmEYu3btMpxOp5GSkmJ88803xmuvvWZERkYakozDhw+f92eyePFiIywszFi5cqXx/fffGxs3bjT+/e9/u5//29/+ZnTo0MFYv369kZubazz11FOG0+k0vv32W8MwDGPu3LlGUFCQ0aNHD2PTpk1GVlaW0bRpU2Pw4MGGYRjG0aNHjQEDBhi9e/c29uzZY+zZs8dwuVxGXl6eIcn4/PPPDcMwjLVr1xqSjPbt2xsbNmwwNm/ebDRu3Njo3Lmz0atXL2Pz5s3G+vXrjYiICGPGjBnu+v7oZ/LLftu1a2dkZGQYX375pXHNNdcYHTp0MAzDMI4fP25MnDjRuOKKK9z1HT9+vLRfKQDnQYCA7ZwdIEpKSoz333/fcDqdxqRJk9zPR0ZGuoOBYRjGggULjNjYWKOkpMQ95nK5jJCQEGP16tWGYRhGdHS08eSTT7qfP3XqlFGnTp3fDRA5OTmGJOP9998/b52//NI7+5f+yZMnjUqVKhkff/yxx2tHjRpl3HLLLYZhGEZqaqrRrFkzj+fvv//+CwaIf/zjH0aTJk2MoqKic577/vvvjcDAQOPHH3/0GO/evbuRmppqGMaZACHJyM3NdT///PPPG5GRke7H5wtuvxcg1qxZ435Nenq6IcnYsWOHe+yOO+4wEhMTS/0zOd9+V6xYYUgyTpw4YRiGYUyZMsVo2bLleX8+AMxjDQRsafny5QoNDdWpU6dUUlKiwYMHa+rUqe7nW7Ro4bHu4YsvvlBubq6qVKnisZ+TJ09qx44dKigo0J49e9SuXTv3cxUqVFCbNm3Omcb4RXZ2tgIDA9W5c+dS152bm6vjx4+rZ8+eHuNFRUVq1aqVJOnrr7/2qEOSEhISLrjfm2++WU8//bQaNmyo3r1769prr9X111+vChUqaOvWrSouLlaTJk083uNyuRQREeF+XKlSJTVq1Mj9ODo6Wvv37y/1ZztbfHy8+9+RkZGqVKmSGjZs6DH26aefSirdz+R8+42OjpYk7d+/XzExMRdVJ4DfR4CALXXt2lWzZ89WcHCwateurQoVPL/qlStX9nhcWFio1q1b6/XXXz9nXzVr1ryoGkJCQky/p7CwUJK0YsUKXXbZZR7POZ3Oi6pDOnM2RE5OjtasWaP3339fd955p5566imtW7dOhYWFCgwMVFZWlgIDAz3eFxoa6v53UFCQx3MOh+N3w9MfOXtfDofjvPsuKSmRZO5n8tv9SnLvB4B3ESBgS5UrV1bjxo1L/fqrrrpKb7zxhmrVqqWwsLDzviY6OlobN25Up06dJEmnT59WVlaWrrrqqvO+vkWLFiopKdG6devUo0ePc57/pQNSXFzsHmvWrJmcTqd27dr1u52Lpk2buheE/uKTTz75w88YEhKi66+/Xtdff72Sk5MVFxenrVu3qlWrViouLtb+/ft1zTXX/OF+fk9wcLDHZ/GW0vxMSsOq+oDyirMwAElDhgxRjRo11LdvX3300UfKy8tTRkaG7rrrLu3evVuSdPfdd2vGjBl6++239c033+jOO++84DUc6tevr2HDhmnkyJF6++233fv873//K0mqV6+eHA6Hli9frp9//lmFhYWqUqWKJk2apAkTJmj+/PnasWOHNm/erH/961+aP3++JGnMmDHavn277r33XuXk5GjhwoV/eEbBvHnz9PLLL2vbtm367rvv9NprrykkJET16tVTkyZNNGTIEA0dOlRvvfWW8vLy9Omnnyo9PV0rVqwo9c+wfv362rJli3JycnTgwAGdOnWq1O+9kNL8TEpbX15enrKzs3XgwAG5XC6v1AeUVwQIQGfm99evX6+YmBj1799fTZs21ahRo3Ty5El3R2LixIm67bbbNGzYMCUkJKhKlSq68cYbL7jf2bNn66abbtKdd96puLg4jR49WseOHZMkXXbZZUpLS9MDDzygyMhIjRs3TpL06KOPavLkyUpPT1fTpk3Vu3dvrVixQg0aNJAkxcTEaMmSJXr77bfVsmVLzZkzR48//vgF66hatapefPFFdezYUfHx8VqzZo2WLVvmXuMwd+5cDR06VBMnTlRsbKz69eunTZs2mVo7MHr0aMXGxqpNmzaqWbOm/ve//5X6vX/kj34mpZGUlKTevXura9euqlmzpv7zn/94rT6gPHIYFzuJCQAAyi06EAAAwDQCBAAAMI0AAQAATCNAAAAA0wgQAADANAIEAAAwjQABAABMI0AAAADTCBAAAMA0AgQAADCNAAEAAEwjQAAAANP+HxQtqoOr+mV6AAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## å¾Œé¢å°±æ˜¯çœ‹æ¨¡å‹çš„çµæœ"],"metadata":{"id":"oFAsEQhrKEeH"}},{"cell_type":"code","source":["idx = 2\n","\n","content_text = y_content_texts[idx]\n","true_sentiment = y_test[idx]\n","pred_df = pd.DataFrame({\n","  'class_names': class_names,\n","  'values': y_pred_probs[idx]\n","})"],"metadata":{"id":"767_qqGCKBmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from textwrap import wrap\n","print(\"\\n\".join(wrap(content_text)))\n","print()\n","print(f'True sentiment: {class_names[true_sentiment]}')"],"metadata":{"id":"vce5JF7uKRCG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506127,"user_tz":-480,"elapsed":17,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"b4fd6d0d-f33d-40af-a824-e5bf3f986cd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ä»Šæ—¥å¤§æºªè€è¡—ä¸€æ—¥éŠå¤§æºªè€è¡—æ€éº¼åƒå…ˆå¹«å¤§å®¶åšé®®åŸæœ¬æƒ³åƒå€‹è±†èŠ±ä½†å¤ªæ’äº†æ²’åƒå¤§æºªè€è¡—è€é˜¿ä¼¯ç¾æ»·è±†å¹²ä½åœ¨å¤§æºªè€è¡—èµ°åˆ°åº•é‹å‹•ä¸­å¿ƒå·¦è½‰æ¨è–¦é †åºè±†åŒ…ç™¾è‘‰é»ƒ\n","é‡‘è›‹ç´ é›æµ·å¸¶è±†å¹²ä»¥ä¸Šæ˜¯æˆ‘å€‘é»çš„å…±è¶…å¤šè¶…é£½è±†åŒ…è¶…å…¥å‘³ç™¾è‘‰å¾ˆå«©å…¶ä»–è »æ™®é€šçš„è¾£é†¬å¾ˆå¥½åƒä½†æœƒè¾£å–”é˜¿å¬¤å°åƒåº—é¦™è…¸ç±³è…¸ä¸€è™Ÿé¤ç±³è…¸ç±³è¡€é¦™è…¸é¦™è…¸çƒ¤éç±³è…¸ç±³è¡€\n","æ˜¯è’¸çš„æˆ‘è¦ºå¾—é¦™è…¸çƒ¤ä¸å¤ è„†ç±³è…¸æˆ‘ä¹Ÿè¦ºå¾—çƒ¤çš„æ¯”è¼ƒå¥½åƒç±³è¡€ä¹Ÿæ²’ä»€éº¼è±¬è¡€ç³•çš„å‘³é“è±¬è¡€æ¹¯æœ‰åŠ å°è…¸æ–™å¾ˆå¤šæ¹¯é ­å…¶å¯¦ä¸éŒ¯å–ä½†æˆ‘é‚„æ˜¯å–œæ­¡æ²™èŒ¶åŠ åˆ°çˆ†çš„è±¬è¡€æ¹¯å…ƒé³¥\n","è›‹é€™å®¶æ‡‰è©²æ˜¯å¤§æºªè€è¡—æœ€ä¾¿å®œé³¥è›‹å…ƒçƒ¤ç‰ç±³å¤§æºªè€è¡—æœ€ä¾¿å®œçƒ¤ç‰ç±³æ•´æ•´æ¯”å°åŒ—ä¾¿å®œå…©å€ç‰ç±³æ˜¯ç³¯ç±³ç‰ç±³æ²’éŒ¯ä¸éå£å‘³åç”œæˆ‘åƒå¥½ä¹…ä¸€ç›´ä»¥ç‚ºä»–æ˜¯ç”œç‰ç±³å…ƒç‚¸ç†±ç‹—\n","æ‹›ç‰Œæ˜¯å¯«ç†±ç‹—æ²’æƒ³åˆ°æ”¶éŒ¢æ”¶å¯èƒ½æ˜¯è£¹ç²‰çš„åƒ¹æ ¼ä¸ä¸€æ¨£æˆ‘å€‘é»å°éš»çš„å†¬ç“œèŒ¶ä½åœ¨è€é˜¿ä¼¯ç¾æ»·è±†å¹²å°é¢ä¸€å€‹é˜¿å¬¤é–‹çš„æœ‰é‡‘å‰æª¸æª¬è·Ÿå†¬ç“œèŒ¶é‚„æœ‰è²¢ä¸¸æ¹¯å†¬ç“œèŒ¶ä¸æœƒåˆ°å¾ˆ\n","ç”œä½†å†¬ç“œå‘³ä¹Ÿæ²’æœ‰åˆ°å¾ˆæ¿ƒéƒä¸éé…è±†å¹²è »é©åˆçš„æˆ‘å€‘å¾å¤§æºªè€è¡—é ­é †è·¯åƒä¸‹å»çš„é †åºé¦™è…¸é³¥è›‹ç‰ç±³ç†±ç‹—å†¬ç“œèŒ¶è±†ä¹¾çµ¦å¤§å®¶åƒè€ƒå–œæ­¡æˆ‘é£Ÿè¨˜å¯ä»¥è¿½è¹¤æˆ‘IG\n","\n","True sentiment: M\n"]}]},{"cell_type":"code","source":["sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n","plt.ylabel('sentiment')\n","plt.xlabel('probability')\n","plt.xlim([0, 1]);"],"metadata":{"id":"UD5hpkf_LC8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506482,"user_tz":-480,"elapsed":365,"user":{"displayName":"æ›¹çç¿°","userId":"00262753423893401071"}},"outputId":"02c5c7ee-e843-4c68-dcd9-8c496ad6c4b2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjgAAAGwCAYAAACkfh/eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgJklEQVR4nO3dfZjVdZ34/9dhYAYEBjCTO0dQCSVF1AhEUswwXFnv2i41EEEya8VyQU1ZQxRSkIwMlrUrSW5cVzaVXG+4NLW4WtnQSxKXgjAFkRR0dUVAkLv5/P7ox/k2DhjnzHFmePN4XNe5Ls/nfM7nvIY3OM/rc+5yWZZlAQCQkCYNPQAAQKkJHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBITtOGHqBUqqur480334zWrVtHLpdr6HEAgH2QZVls2rQpOnXqFE2alO68SzKB8+abb0ZVVVVDjwEAFGHt2rVx2GGHlex4yQRO69atI+Ivf0CVlZUNPA0AsC82btwYVVVV+d/jpZJM4Ox+WqqyslLgAMB+ptQvL/EiYwAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5yXyS8W6nfe/+KKtoERERS35waQNPAwA0BGdwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQ0isAZMWJE5HK5mDx5co3tDz/8cORyuQaaCgDYXzWKwImIaN68edx+++3x3nvvNfQoAMB+rtEEzsCBA6NDhw4xadKkhh4FANjPNZrAKSsri9tuuy2mT58ef/7zn//m/tu2bYuNGzfWuAAARDSiwImIuOCCC+KEE06I8ePH/819J02aFG3atMlfqqqq6mFCAGB/0KgCJyLi9ttvjzlz5sSKFSs+dr+xY8fG+++/n7+sXbu2niYEABq7Rhc4p512WgwaNCjGjh37sftVVFREZWVljQsAQERE04YeYE8mT54cJ5xwQhx99NENPQoAsB9qdGdwIiJ69uwZQ4cOjWnTpjX0KADAfqhRBk5ExIQJE6K6urqhxwAA9kON4imq2bNn19rWtWvX2LZtW/0PAwDs9xrtGRwAgGIJHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDlNG3qAUvvN978WlZWVDT0GANCAnMEBAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJIjcACA5AgcACA5AgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBITtOGHqDU1k4+OVo3L2voMaBgh9+0rKFHAEiGMzgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAySkqcEaOHBmbNm2qtf2DDz6IkSNH1nkoAIC6KCpw5syZE1u3bq21fevWrTF37tw6DwUAUBdNC9l548aNkWVZZFkWmzZtiubNm+dv27VrVyxYsCAOPfTQkg8JAFCIggKnbdu2kcvlIpfLRffu3Wvdnsvl4pZbbinZcAAAxSgocH79619HlmVxxhlnxEMPPRQHH3xw/rby8vLo0qVLdOrUqeRDAgAUoqDAGTBgQERErF69OqqqqqJJE2/CAgAan4ICZ7cuXbrEhg0b4vnnn4+33347qqura9x+6aWXlmQ4AIBiFBU4jz76aAwdOjQ2b94clZWVkcvl8rflcjmBAwA0qKKeY7rmmmti5MiRsXnz5tiwYUO89957+cv//d//lXpGAICCFBU4b7zxRnznO9+Jgw46qNTzAADUWVGBM2jQoHjhhRdKPQsAQEkU9RqcwYMHx3XXXRfLly+Pnj17RrNmzWrcfu6555ZkOACAYhQVON/4xjciImLChAm1bsvlcrFr1666TQUAUAdFBc5H3xYOANCY1PmT+j788MNSzAEAUDJFBc6uXbti4sSJ0blz52jVqlWsWrUqIiLGjRsXP/vZz0o6IABAoYoKnFtvvTVmz54dU6ZMifLy8vz24447LmbOnFmy4QAAilFU4MydOzd++tOfxtChQ6OsrCy/vVevXvHHP/6xZMMBABSj6A/669atW63t1dXVsWPHjjoPBQBQF0UFzmc/+9n4r//6r1rbH3zwwTjxxBPrPBQAQF0U9Tbxm266KYYPHx5vvPFGVFdXx/z582PlypUxd+7ceOyxx0o9IwBAQYo6g3PeeefFo48+Gk8//XS0bNkybrrpplixYkU8+uijceaZZ5Z6RgCAghR1Bici4tRTT42nnnqqlLMAAJRE0YGz2+bNm2t9snFlZWVdDwsAULSinqJavXp1DB48OFq2bBlt2rSJdu3aRbt27aJt27bRrl27Us8IAFCQos7gXHLJJZFlWdxzzz3Rvn37yOVypZ4LAKBoRQXOSy+9FEuWLImjjz661PMAANRZUU9Rff7zn4+1a9eWehYAgJIoKnBmzpwZt99+e8yZMyeWLFkS//M//1Pjsq9GjBgRuVwuvvWtb9W6bdSoUZHL5WLEiBHFjAgAHMCKeorqf//3f+PVV1+Nyy67LL8tl8tFlmWRy+Vi165d+3ysqqqqmDdvXvzoRz+KFi1aRETEhx9+GP/+7/8ehx9+eDHjAQAHuKICZ+TIkXHiiSfG/fffX+cXGZ900knx6quvxvz582Po0KERETF//vw4/PDD44gjjij6uADAgauowFmzZk088sgje/zCzWKMHDkyZs2alQ+ce+65Jy677LJYuHDhXu+zbdu22LZtW/76xo0bSzILALD/K+o1OGeccUa89NJLJRvikksuiWeffTbWrFkTa9asiUWLFsUll1zysfeZNGlStGnTJn+pqqoq2TwAwP6tqDM455xzTowePTqWLVsWPXv2jGbNmtW4/dxzzy3oeJ/+9Kdj8ODBMXv27MiyLAYPHhyHHHLIx95n7NixMWbMmPz1jRs3ihwAICKKDJzd73qaMGFCrdsKfZHxbiNHjoyrrroqIiJmzJjxN/evqKiIioqKgh8HAEhfUYHz0e+eKoWzzjortm/fHrlcLgYNGlTy4wMAB446f9lmqZSVlcWKFSvy/w0AUKx9Dpxp06bFFVdcEc2bN49p06Z97L7f+c53ihrGt5ADAKWQy7Is25cdjzjiiHjhhRfiU5/61Md+Pk0ul4tVq1aVbMB9tXHjxmjTpk38fmyPaN3cGSD2P4fftKyhRwCod7t/f7///vslPdGxz2dwVq9evcf/BgBobIr6HJwJEybEli1bam3funXrHt9ZBQBQn4oKnFtuuSU2b95ca/uWLVvilltuqfNQAAB1UVTg7P5SzY966aWX4uCDD67zUAAAdVHQ28TbtWsXuVwucrlcdO/evUbk7Nq1KzZv3pz/EEAAgIZSUODceeedkWVZjBw5Mm655ZZo06ZN/rby8vLo2rVr9OvXr+RDAgAUoqDAGT58eET85S3jp5xySq3voAIAaAyK+iTjAQMGRHV1dbz88svx9ttv1/rqhtNOO60kwwEAFKOowFm8eHEMGTIk1qxZEx/9nMBiv2wTAKBUiv428d69e8fjjz8eHTt23OM7qgAAGkpRgfOnP/0pHnzwwejWrVup5wEAqLOiPgenb9++8corr5R6FgCAkijqDM63v/3tuOaaa2L9+vXRs2fPWu+mOv7440syHABAMYoKnH/4h3+IiIiRI0fmt+VyufwnHHuRMQDQkIoKHN8mDgA0ZkUFTpcuXUo9BwBAyRT1IuOIiHvvvTf69+8fnTp1ijVr1kTEX77K4T//8z9LNhwAQDGKCpy77rorxowZE2effXZs2LAh/5qbtm3bxp133lnK+QAAClZU4EyfPj3uvvvuuPHGG6OsrCy/vXfv3rFs2bKSDQcAUIyiAmf16tVx4okn1tpeUVERH3zwQZ2HAgCoi6IC54gjjoilS5fW2v7EE09Ejx496joTAECdFPUuqjFjxsSoUaPiww8/jCzL4vnnn4/7778/Jk2aFDNnziz1jAAABSkqcC6//PJo0aJFfO9734stW7bEkCFDonPnzvHjH/84Lr744lLPCABQkKICZ+vWrXHBBRfE0KFDY8uWLfH73/8+Fi1aFIcddlip5wMAKFhRr8E577zzYu7cuRERsX379jj33HNj6tSpcf7558ddd91V0gEBAApVVOD87ne/i1NPPTUiIh588MFo3759rFmzJubOnRvTpk0r6YAAAIUqKnC2bNkSrVu3joiIX/7yl/GVr3wlmjRpEieffHL+U40BABpKUYHTrVu3ePjhh2Pt2rXx5JNPxpe//OWIiHj77bejsrKypAMCABSqqMC56aab4tprr42uXbtG3759o1+/fhHxl7M5e/oAQACA+lTUu6i++tWvxhe+8IVYt25d9OrVK7/9S1/6UlxwwQUlGw4AoBhFBU5ERIcOHaJDhw41tvXp06fOAwEA1FVRT1EBADRmAgcASI7AAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJJT9HdRNVZVNyyOysrKhh4DAGhAzuAAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkp2lDD1BqZ/7kzGjaIrkfC6CWRd9e1NAjQKPlDA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQnEYVOCNGjIhcLhe5XC7Ky8ujW7duMWHChNi5c2dDjwYA7EeaNvQAH3XWWWfFrFmzYtu2bbFgwYIYNWpUNGvWLMaOHdvQowEA+4lGdQYnIqKioiI6dOgQXbp0iX/8x3+MgQMHxiOPPFJrv23btsXGjRtrXAAAIhph4HxUixYtYvv27bW2T5o0Kdq0aZO/VFVVNcB0AEBj1GgDJ8uyePrpp+PJJ5+MM844o9btY8eOjffffz9/Wbt2bQNMCQA0Ro3uNTiPPfZYtGrVKnbs2BHV1dUxZMiQuPnmm2vtV1FRERUVFfU/IADQ6DW6wPniF78Yd911V5SXl0enTp2iadNGNyIA0Mg1unpo2bJldOvWraHHAAD2Y432NTgAAMUSOABAchrVU1SzZ89u6BEAgAQ4gwMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMkROABAcgQOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACSnaUMPUGpPfeupqKysbOgxAIAG5AwOAJAcgQMAJEfgAADJETgAQHIEDgCQHIEDACRH4AAAyRE4AEByBA4AkByBAwAkR+AAAMlJ5ruosiyLiIiNGzc28CQAwL7a/Xt79+/xUkkmcN59992IiKiqqmrgSQCAQr377rvRpk2bkh0vmcA5+OCDIyLi9ddfL+kfEIXbuHFjVFVVxdq1a32zeyNgPRoPa9F4WIvG4/3334/DDz88/3u8VJIJnCZN/vJyojZt2vjL2khUVlZai0bEejQe1qLxsBaNx+7f4yU7XkmPBgDQCAgcACA5yQRORUVFjB8/PioqKhp6lAOetWhcrEfjYS0aD2vReHxSa5HLSv2+LACABpbMGRwAgN0EDgCQHIEDACRH4AAAydmvAmfGjBnRtWvXaN68efTt2zeef/75j93/gQceiGOOOSaaN28ePXv2jAULFtTTpOkrZC3uvvvuOPXUU6Ndu3bRrl27GDhw4N9cOwpT6L+N3ebNmxe5XC7OP//8T3bAA0iha7Fhw4YYNWpUdOzYMSoqKqJ79+7+X1Uiha7FnXfeGUcffXS0aNEiqqqqYvTo0fHhhx/W07Tp+s1vfhPnnHNOdOrUKXK5XDz88MN/8z4LFy6Mk046KSoqKqJbt24xe/bswh8420/MmzcvKy8vz+65557sD3/4Q/aNb3wja9u2bfbWW2/tcf9FixZlZWVl2ZQpU7Lly5dn3/ve97JmzZply5Ytq+fJ01PoWgwZMiSbMWNG9uKLL2YrVqzIRowYkbVp0yb785//XM+Tp6nQ9dht9erVWefOnbNTTz01O++88+pn2MQVuhbbtm3LevfunZ199tnZs88+m61evTpbuHBhtnTp0nqePD2FrsV9992XVVRUZPfdd1+2evXq7Mknn8w6duyYjR49up4nT8+CBQuyG2+8MZs/f34WEdkvfvGLj91/1apV2UEHHZSNGTMmW758eTZ9+vSsrKwse+KJJwp63P0mcPr06ZONGjUqf33Xrl1Zp06dskmTJu1x/wsvvDAbPHhwjW19+/bNvvnNb36icx4ICl2Lj9q5c2fWunXrbM6cOZ/UiAeUYtZj586d2SmnnJLNnDkzGz58uMApkULX4q677sqOPPLIbPv27fU14gGj0LUYNWpUdsYZZ9TYNmbMmKx///6f6JwHmn0JnO9+97vZscceW2PbRRddlA0aNKigx9ovnqLavn17LFmyJAYOHJjf1qRJkxg4cGD89re/3eN9fvvb39bYPyJi0KBBe92ffVPMWnzUli1bYseOHSX/YrUDUbHrMWHChDj00EPj61//en2MeUAoZi0eeeSR6NevX4waNSrat28fxx13XNx2222xa9eu+ho7ScWsxSmnnBJLlizJP421atWqWLBgQZx99tn1MjP/T6l+f+8XX7b5zjvvxK5du6J9+/Y1trdv3z7++Mc/7vE+69ev3+P+69ev/8TmPBAUsxYfdf3110enTp1q/QWmcMWsx7PPPhs/+9nPYunSpfUw4YGjmLVYtWpV/OpXv4qhQ4fGggUL4pVXXokrr7wyduzYEePHj6+PsZNUzFoMGTIk3nnnnfjCF74QWZbFzp0741vf+lb88z//c32MzF/Z2+/vjRs3xtatW6NFixb7dJz94gwO6Zg8eXLMmzcvfvGLX0Tz5s0bepwDzqZNm2LYsGFx9913xyGHHNLQ4xzwqqur49BDD42f/vSn8bnPfS4uuuiiuPHGG+MnP/lJQ492wFm4cGHcdttt8a//+q/xu9/9LubPnx+PP/54TJw4saFHo0j7xRmcQw45JMrKyuKtt96qsf2tt96KDh067PE+HTp0KGh/9k0xa7HbHXfcEZMnT46nn346jj/++E9yzANGoevx6quvxmuvvRbnnHNOflt1dXVERDRt2jRWrlwZRx111Cc7dKKK+bfRsWPHaNasWZSVleW39ejRI9avXx/bt2+P8vLyT3TmVBWzFuPGjYthw4bF5ZdfHhERPXv2jA8++CCuuOKKuPHGG6NJE+cD6svefn9XVlbu89mbiP3kDE55eXl87nOfi2eeeSa/rbq6Op555pno16/fHu/Tr1+/GvtHRDz11FN73Z99U8xaRERMmTIlJk6cGE888UT07t27PkY9IBS6Hsccc0wsW7Ysli5dmr+ce+658cUvfjGWLl0aVVVV9Tl+Uor5t9G/f/945ZVX8pEZEfHyyy9Hx44dxU0dFLMWW7ZsqRUxu8Mz85WN9apkv78Le/1zw5k3b15WUVGRzZ49O1u+fHl2xRVXZG3bts3Wr1+fZVmWDRs2LLvhhhvy+y9atChr2rRpdscdd2QrVqzIxo8f723iJVLoWkyePDkrLy/PHnzwwWzdunX5y6ZNmxrqR0hKoevxUd5FVTqFrsXrr7+etW7dOrvqqquylStXZo899lh26KGHZt///vcb6kdIRqFrMX78+Kx169bZ/fffn61atSr75S9/mR111FHZhRde2FA/QjI2bdqUvfjii9mLL76YRUQ2derU7MUXX8zWrFmTZVmW3XDDDdmwYcPy++9+m/h1112XrVixIpsxY0babxPPsiybPn16dvjhh2fl5eVZnz59ssWLF+dvGzBgQDZ8+PAa+//85z/PunfvnpWXl2fHHnts9vjjj9fzxOkqZC26dOmSRUSty/jx4+t/8EQV+m/jrwmc0ip0Lf77v/8769u3b1ZRUZEdeeSR2a233prt3LmznqdOUyFrsWPHjuzmm2/OjjrqqKx58+ZZVVVVduWVV2bvvfde/Q+emF//+td7/B2w+89/+PDh2YABA2rd54QTTsjKy8uzI488Mps1a1bBj5vLMufeAIC07BevwQEAKITAAQCSI3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCB6hXXbt2jTvvvLNOx5g9e3a0bdv2Y/e5+eab44QTTshfHzFiRJx//vn566effnr80z/9U53mABovgQMk6dprr631hX1/bf78+TFx4sT89VKEF9B4NG3oAYA0bN++vVF9A3arVq2iVatWe7394IMPrsdpgPrmDA6wR6effnpcddVVcdVVV0WbNm3ikEMOiXHjxsXur6/r2rVrTJw4MS699NKorKyMK664IiIiHnrooTj22GOjoqIiunbtGj/84Q9rHXvTpk3xta99LVq2bBmdO3eOGTNm1Lh96tSp0bNnz2jZsmVUVVXFlVdeGZs3b651nIcffjg+85nPRPPmzWPQoEGxdu3a/G0ffYpqTz/f7qeoTj/99FizZk2MHj06crlc5HK5+OCDD6KysjIefPDBWo/ZsmXL2LRp0z79OQINQ+AAezVnzpxo2rRpPP/88/HjH/84pk6dGjNnzszffscdd0SvXr3ixRdfjHHjxsWSJUviwgsvjIsvvjiWLVsWN998c4wbNy5mz55d47g/+MEP8ve74YYb4uqrr46nnnoqf3uTJk1i2rRp8Yc//CHmzJkTv/rVr+K73/1ujWNs2bIlbr311pg7d24sWrQoNmzYEBdffHFRP+f8+fPjsMMOiwkTJsS6deti3bp10bJly7j44otj1qxZNfadNWtWfPWrX43WrVsX9VhAPanjt6ADiRowYEDWo0ePrLq6Or/t+uuvz3r06JFlWZZ16dIlO//882vcZ8iQIdmZZ55ZY9t1112Xffazn81f79KlS3bWWWfV2Oeiiy7K/u7v/m6vszzwwAPZpz71qfz1WbNmZRGRLV68OL9txYoVWURkzz33XJZlWTZ+/PisV69e+duHDx+enXfeeTV+vquvvrrGXD/60Y9qPO5zzz2XlZWVZW+++WaWZVn21ltvZU2bNs0WLly411mBxsEZHGCvTj755Mjlcvnr/fr1iz/96U+xa9euiIjo3bt3jf1XrFgR/fv3r7Gtf//+Ne6z+zh/rV+/frFixYr89aeffjq+9KUvRefOnaN169YxbNiwePfdd2PLli35fZo2bRqf//zn89ePOeaYaNu2bY3j1FWfPn3i2GOPjTlz5kRExL/9279Fly5d4rTTTivZYwCfDIEDFK1ly5YlP+Zrr70Wf//3fx/HH398PPTQQ7FkyZL8a3S2b99e8sf7Wy6//PL8U2yzZs2Kyy67rEb0AY2TwAH26rnnnqtxffHixfGZz3wmysrK9rh/jx49YtGiRTW2LVq0KLp3717jPosXL6513B49ekRExJIlS6K6ujp++MMfxsknnxzdu3ePN998s9Zj7dy5M1544YX89ZUrV8aGDRvyxylUeXl5jbNMu11yySWxZs2amDZtWixfvjyGDx9e1PGB+iVwgL16/fXXY8yYMbFy5cq4//77Y/r06XH11Vfvdf9rrrkmnnnmmZg4cWK8/PLLMWfOnPiXf/mXuPbaa2vst2jRopgyZUq8/PLLMWPGjHjggQfyx+3WrVvs2LEjpk+fHqtWrYp77703fvKTn9R6rGbNmsW3v/3teO6552LJkiUxYsSIOPnkk6NPnz5F/axdu3aN3/zmN/HGG2/EO++8k9/erl27+MpXvhLXXXddfPnLX47DDjusqOMD9UvgAHt16aWXxtatW6NPnz4xatSouPrqq/NvB9+Tk046KX7+85/HvHnz4rjjjoubbropJkyYECNGjKix3zXXXBMvvPBCnHjiifH9738/pk6dGoMGDYqIiF69esXUqVPj9ttvj+OOOy7uu+++mDRpUq3HOuigg+L666+PIUOGRP/+/aNVq1bxH//xH0X/rBMmTIjXXnstjjrqqPj0pz9d47avf/3rsX379hg5cmTRxwfqVy7L/v8PtQD4K6effnqccMIJPt03Iu69994YPXp0vPnmm43qwwyBvfNJxgB7sWXLlli3bl1Mnjw5vvnNb4ob2I94igpgL6ZMmRLHHHNMdOjQIcaOHdvQ4wAF8BQVAJAcZ3AAgOQIHAAgOQIHAEiOwAEAkiNwAIDkCBwAIDkCBwBIjsABAJLz/wGAIODhJFo/GQAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# å„²å­˜æ¨¡å‹"],"metadata":{"id":"krdJ5hEuNSlu"}},{"cell_type":"code","source":["save_path = \"model_file/sentiment_classification_model.pth\"\n","torch.save(model.state_dict(), save_path)"],"metadata":{"id":"zz0gtCzWNSEN"},"execution_count":null,"outputs":[]}]}